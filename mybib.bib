@article{RefWorks:RefID:187-susskind1986expert,
author={Susskind,Richard E.},
title={EXPERT SYSTEMS IN LAW: A JURISPRUDENTIAL APPROACH TO ARTIFICIAL INTELLIGENCE AND LEGAL REASONING},
journal={Modern law review},
volume={49},
number={2},
pages={168–194},
keywords={Law; Used}, issn={0026-7961},
doi={10.1111/j.1468-2230.1986.tb01683.x},
year={1986},
url={https://api.istex.fr/ark:/67375/WNG-0FV7JD0B-2/fulltext.pdf},
}

@book{RefWorks:RefID:186-navarro2014deontic,
author={Navarro,Pablo E. and Rodríguez,Jorge L.},
title={Deontic Logic and Legal Systems},
series={Cambridge Introductions to Philosophy and Law},
abstract={A considerable number of books and papers have analyzed normative concepts using new techniques developed by logicians; however, few have bridged the gap between the English legal culture and the Continental (i.e. European and Latin American) tradition in legal philosophy. This book addresses this issue by offering an introductory study on the many possibilities that logical analysis offers the study of legal systems. The volume is divided into two sections: the first covers the basic aspects of classical and deontic logic and its connections, advancing an explanation of the most important topics of the discipline by comparing different systems of deontic logic and exploring some of the most important paradoxes in its domain. The second section deals with the role of logic in the analysis of legal systems by discussing in what sense deontic logic and the logic of norm-propositions are useful tools for a proper understanding of the systematic structure of law.},
publisher={Cambridge University Press},
address={New York},
edition={1},
keywords={Law; Used},
isbn={0521767393},
url={http://dx.doi.org/10.1017/CBO9781139032711},
doi={10.1017/CBO9781139032711},
year={2014},
translator={Anonymous },
}

@article{RefWorks:RefID:185-2019transformerxl,
author={Zihang Dai and Zhilin Yang and Yiming Yang and Jaime Carbonell and Quoc Le and Ruslan Salakhutdinov},
title={Transformer-XL: Attentive Language Models beyond a Fixed-Length Context},
journal={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
keywords={Transformer; Used},
doi={10.18653/v1/p19-1285},
year={2019},
url={https://www.aclweb.org/anthology/P19-1285.pdf},
}

@misc{RefWorks:RefID:184-zaheerbig,
author={Zaheer,Manzil and Guruganesh,Guru and Dubey,Avinava and Ainslie,Joshua and Alberti,Chris and Ontanon,Santiago and Pham,Philip and Ravula,Anirudh and Wang,Qifan and Yang,Li and Ahmed,Amr},
title={Big Bird: Transformers for Longer Sequences},
abstract={Transformers-based models, such as BERT, have been one of the most successful deep learning models for NLP. Unfortunately, one of their core limitations is the quadratic dependency (mainly in terms of memory) on the sequence length due to their full attention mechanism. To remedy this, we propose, BIGBIRD, a sparse attention mechanism that reduces this quadratic dependency to linear. We show that BIGBIRD is a universal approximator of sequence functions and is Turing complete, thereby preserving these properties of the quadratic, full attention model. Along the way, our theoretical analysis reveals some of the benefits of having O(1) global tokens (such as CLS), that attend to the entire sequence as part of the sparse attention mechanism. The proposed sparse attention can handle sequences of length up to 8x of what was previously possible using similar hardware. As a consequence of the capability to handle longer context, BIGBIRD drastically improves performance on various NLP tasks such as question answering and summarization. We also propose novel applications to genomics data.},
keywords={Transformer; Used},
}

@misc{RefWorks:RefID:183-beltagylongformer,
author={Beltagy,Iz and Peters,Matthew E. and Cohan,Arman},
title={Longformer: The Long-Document Transformer},
abstract={Transformer-based models are unable to process long sequences due to their self-attention operation, which scales quadratically with the sequence length. To address this limitation, we introduce the Longformer with an attention mechanism that scales linearly with sequence length, making it easy to process documents of thousands of tokens or longer. Longformer's attention mechanism is a drop-in replacement for the standard self-attention and combines a local windowed attention with a task motivated global attention. Following prior work on long-sequence transformers, we evaluate Longformer on character-level language modeling and achieve state-of-the-art results on text8 and enwik8. In contrast to most prior work, we also pretrain Longformer and finetune it on a variety of downstream tasks. Our pretrained Longformer consistently outperforms RoBERTa on long document tasks and sets new state-of-the-art results on Wiki-Hop and TriviaQA. We finally introduce the Longformer-Encoder-Decoder (LED), a Longformer variant for supporting long document generative sequence-to-sequence tasks, and demonstrate its effectiveness on the arXiv summarization dataset. 1},
keywords={Used; Document; Transformer},
}

@article{RefWorks:RefID:167-gardazi2025bert,
author={Gardazi,Nadia M. and Daud,Ali and Malik,Muhammad K. and Bukhari,Amal and Alsahfi,Tariq and Alshemaimri,Bader},
title={BERT applications in natural language processing: a review},
journal={The Artificial intelligence review},
volume={58},
number={6},
pages={166},
note={Replaces 91.},
abstract={BERT (Bidirectional Encoder Representations from Transformers) has revolutionized Natural Language Processing (NLP) by significantly enhancing the capabilities of language models. This review study examines the complex nature of BERT, including its structure, utilization in different NLP tasks, and the further development of its design via modifications. The study thoroughly analyses the methodological aspects, conducting a comprehensive analysis of the planning process, the implemented procedures, and the criteria used to decide which data to include or exclude in the evaluation framework. In addition, the study thoroughly examines the influence of BERT on several NLP tasks, such as Sentence Boundary Detection, Tokenization, Grammatical Error Detection and Correction, Dependency Parsing, Named Entity Recognition, Part of Speech Tagging, Question Answering Systems, Machine Translation, Sentiment analysis, fake review detection and Cross-lingual transfer learning. The review study adds to the current literature by integrating ideas from multiple sources, explicitly emphasizing the problems and prospects in BERT-based models. The objective is to comprehensively comprehend BERT and its implementations, targeting both experienced researchers and novices in the domain of NLP. Consequently, the present study is expected to inspire more research endeavors, promote innovative adaptations of BERT, and deepen comprehension of its extensive capabilities in various NLP applications. The results presented in this research are anticipated to influence the advancement of future language models and add to the ongoing discourse on enhancing technology for understanding natural language.},
keywords={LLM; Used}, issn={1573-7462},
doi={10.1007/s10462-025-11162-5},
year={2025},
url={https://link.springer.com/article/10.1007/s10462-025-11162-5},
}

@conference{RefWorks:RefID:166-mochales2009argumentation,
author={Mochales Palau,Raquel and Moens,Marie-Francine},
editor={ },
title={Argumentation mining: the detection, classification and structure of arguments in text},
booktitle={Twelfth international conference on artificial intelligence and law (ICAIL 2009)},
publisher={ACM},
pages={98–109},
abstract={Argumentation is the process by which arguments are constructed and handled. Argumentation constitutes a major
component of human intelligence. The ability to engage in
argumentation is essential for humans to understand new
problems, to perform scientific reasoning, to express, to clarify and to defend their opinions in their daily lives. Argumentation mining aims to detect the arguments presented
in a text document, the relations between them and the internal structure of each individual argument. In this paper
we analyse the main research questions when dealing with
argumentation mining and the different methods we have studied and developed in order to successfully confront the challenges of argumentation mining in legal texts.},
keywords={Law; Used},
url={https://lirias.kuleuven.be/handle/123456789/234784},
doi={10.1145/1568234.1568246},
publisher={ACM},
year={2009},
}

@inbook{RefWorks:RefID:165-bhattacharya2019comparative,
author={Bhattacharya,Paheli and Hiware,Kaustubh and Rajgaria,Subham and Pochhi,Nilay and Ghosh,Kripabandhu and Ghosh,Saptarshi},
title={A Comparative Study of Summarization Algorithms Applied to Legal Case Judgments},
booktitle ={Advances in Information Retrieval},
publisher={Springer International Publishing AG},
address={Switzerland},
volume={11437},
pages={413–428},
abstract={Summarization of legal case judgments is an important problem because the huge length and complexity of such documents make them difficult to read as a whole. Many summarization algorithms have been proposed till date, both for general text documents and a few specifically targeted to summarizing legal documents of various countries. However, to our knowledge, there has not been any systematic comparison of the performances of different algorithms in summarizing legal case documents. In this paper, we perform the first such systematic comparison of summarization algorithms applied to legal judgments. We experiment on a large set of Indian Supreme Court judgments, and a large variety of summarization algorithms including both unsupervised and supervised ones. We assess how well domain-independent summarization approaches perform on legal case judgments, and how approaches specifically designed for legal case documents of other countries (e.g., Canada, Australia) generalize to Indian Supreme Court documents. Apart from quantitatively evaluating summaries by comparing with gold standard summaries, we also give important qualitative insights on the performance of different algorithms from the perspective of a law expert.},
keywords={Law; Used},
isbn={3030157113},
url={http://ebookcentral.proquest.com/lib/SITE_ID/reader.action?docID=5925099&ppg=432},
doi={10.1007/978-3-030-15712-8_27},
year={2019},
translator={Anonymous },
}

@article{RefWorks:RefID:164-aletras2016predicting,
author={Aletras,Nikolaos and Tsarapatsanis,Dimitrios and Preotiuc-Pietro,Daniel and Lampos,Vasileios},
title={Predicting judicial decisions of the European Court of Human Rights: a Natural Language Processing perspective},
journal={PeerJ Computer Science},
volume={2},
pages={e93},
abstract={Recent advances in Natural Language Processing and Machine Learning provide us with the tools to build predictive models that can be used to unveil patterns driving judicial decisions. This can be useful, for both lawyers and judges, as an assisting tool to rapidly identify cases and extract patterns which lead to certain decisions. This paper presents the first systematic study on predicting the outcome of cases tried by the European Court of Human Rights based solely on textual content. We formulate a binary classification task where the input of our classifiers is the textual content extracted from a case and the target output is the actual judgment as to whether there has been a violation of an article of the convention of human rights. Textual information is represented using contiguous word sequences, i.e., N-grams, and topics. Our models can predict the court’s decisions with a strong accuracy (79\% on average). Our empirical analysis indicates that the formal facts of a case are the most important predictive factor. This is consistent with the theory of legal realism suggesting that judicial decision-making is significantly affected by the stimulus of the facts. We also observe that the topical content of a case is another important feature in this classification task and explore this relationship further by conducting a qualitative analysis.},
keywords={Law; Used}, issn={2376-5992},
doi={10.7717/peerj-cs.93},
year={2016},
url={https://www.proquest.com/docview/1950132458},
}

@conference{RefWorks:RefID:162-lairgi2024knowledge,
author={Lairgi,Yassir and Moncla,Ludovic and Cazabet,R'emy and Benabdeslem,Khalid and Cl'eau,Pierre},
editor={ },
title={Knowledge Graph Construction Using Large Language Models},
booktitle={Journee nationale sur la fouille de textes},
address={Lyon, France},
keywords={Knowledge Graph; LLM; Used},
url={https://hal.science/hal-04607294},
year={2024},
}

@article{RefWorks:RefID:160-xu2024large,
author={Xu,Derong and Chen,Wei and Peng,Wenjun and Zhang,Chao and Xu,Tong and Zhao,Xiangyu and Wu,Xian and Zheng,Yefeng and Wang,Yang and Chen,Enhong},
title={Large language models for generative information extraction: a survey},
journal={Frontiers of Computer Science},
volume={18},
number={6},
pages={186357},
abstract={Information Extraction (IE) aims to extract structural knowledge from plain natural language texts. Recently, generative Large Language Models (LLMs) have demonstrated remarkable capabilities in text understanding and generation. As a result, numerous works have been proposed to integrate LLMs for IE tasks based on a generative paradigm. To conduct a comprehensive systematic review and exploration of LLM efforts for IE tasks, in this study, we survey the most recent advancements in this field. We first present an extensive overview by categorizing these works in terms of various IE subtasks and techniques, and then we empirically analyze the most advanced methods and discover the emerging trend of IE tasks with LLMs. Based on a thorough review conducted, we identify several insights in technique and promising research directions that deserve further exploration in future studies. We maintain a public repository and consistently update related works and resources on GitHub (LLM4IE repository).},
keywords={LLM; Information Extraction; Used}, issn={2095-2228},
doi={10.1007/s11704-024-40555-y},
year={2024},
url={https://link.springer.com/article/10.1007/s11704-024-40555-y},
}

@book{RefWorks:RefID:159-ashley2017artificial,
author={Ashley,Kevin D.},
title={Artificial Intelligence and Legal Analytics},
abstract={The field of artificial intelligence (AI) and the law is on the cusp of a revolution that began with text analytic programs like IBM's Watson and Debater and the open-source information management architectures on which they are based. Today, new legal applications are beginning to appear and this book - designed to explain computational processes to non-programmers - describes how they will change the practice of law, specifically by connecting computational models of legal reasoning directly with legal text, generating arguments for and against particular outcomes, predicting outcomes and explaining these predictions with reasons that legal professionals will be able to evaluate for themselves. These legal applications will support conceptual legal information retrieval and allow cognitive computing, enabling a collaboration between humans and computers in which each does what it can do best. Anyone interested in how AI is changing the practice of law should read this illuminating work.},
publisher={Cambridge University Press},
keywords={Law; Used},
isbn={1316622819},
url={http://dx.doi.org/10.1017/9781316761380},
doi={10.1017/9781316761380},
year={2017},
translator={Anonymous },
}

@conference{RefWorks:RefID:158-lewis2020retrievalaugmented,
author={Lewis,PSH and Perez,E. and Piktus,A. and Petroni,F. and Karpukhin,V. and Goyal,N. and Küttler,H. and Lewis,M. and Yih,W-T and Rocktäschel,T. and Riedel,S. and Kiela,D.},
editor={ },
title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
booktitle={Advances in Neural Information Processing Systems},
publisher={Curran Associates, Inc.},
pages={9459–9474},
abstract={Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
keywords={Retrieval Augmented Generation; Used},
url={https://discovery.ucl.ac.uk/id/eprint/10100504},
publisher={Curran Associates, Inc.},
year={2020},
}

@article{RefWorks:RefID:157-2017reading,
author={Danqi Chen and Adam Fisch and Jason Weston and Antoine Bordes},
title={Reading Wikipedia to Answer Open-Domain Questions},
journal={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
abstract={This paper proposes to tackle open domain question answering using
Wikipedia as the unique knowledge
source: the answer to any factoid question
is a text span in a Wikipedia article.
This task of machine reading at scale
combines the challenges of document retrieval (finding the relevant articles) with
that of machine comprehension of text
(identifying the answer spans from those
articles). Our approach combines a search
component based on bigram hashing
and TF-IDF matching with a multi-layer
recurrent neural network model trained to
detect answers in Wikipedia paragraphs.
Our experiments on multiple existing QA
datasets indicate that (1) both modules
are highly competitive with respect to
existing counterparts and (2) multitask
learning using distant supervision on
their combination is an effective complete
system on this challenging task.},
keywords={Question and Answer; Used},
doi={10.18653/v1/p17-1171},
year={2017},
url={https://www.aclweb.org/anthology/P17-1171.pdf},
}

@article{RefWorks:RefID:156-gambhir2017recent,
author={Gambhir,Mahak and Gupta,Vishal},
title={Recent automatic text summarization techniques: a survey},
journal={The Artificial intelligence review},
volume={47},
number={1},
pages={1–66},
abstract={As information is available in abundance for every topic on internet, condensing the important information in the form of summary would benefit a number of users. Hence, there is growing interest among the research community for developing new approaches to automatically summarize the text. Automatic text summarization system generates a summary, i.e. short length text that includes all the important information of the document. Since the advent of text summarization in 1950s, researchers have been trying to improve techniques for generating summaries so that machine generated summary matches with the human made summary. Summary can be generated through extractive as well as abstractive methods. Abstractive methods are highly complex as they need extensive natural language processing. Therefore, research community is focusing more on extractive summaries, trying to achieve more coherent and meaningful summaries. During a decade, several extractive approaches have been developed for automatic summary generation that implements a number of machine learning and optimization techniques. This paper presents a comprehensive survey of recent text summarization extractive approaches developed in the last decade. Their needs are identified and their advantages and disadvantages are listed in a comparative manner. A few abstractive and multilingual text summarization approaches are also covered. Summary evaluation is another challenging issue in this research field. Therefore, intrinsic as well as extrinsic both the methods of summary evaluation are described in detail along with text summarization evaluation conferences and workshops. Furthermore, evaluation results of extractive summarization approaches are presented on some shared DUC datasets. Finally this paper concludes with the discussion of useful future directions that can help researchers to identify areas where further research is needed.},
keywords={Summarization; Survey; Used}, issn={0269-2821},
doi={10.1007/s10462-016-9475-9},
year={2017},
url={https://link.springer.com/article/10.1007/s10462-016-9475-9},
}

@report{RefWorks:RefID:154-knublauch2017shapes,
author={Knublauch,Holger and Kontokostas,Dimitris},
title={Shapes Constraint Language (SHACL)},
journal={w3.org},
note={Recommendation},
keywords={Knowledge Graph; Used},
url={https://www.w3.org/TR/shacl/},
year={2017},
}

@article{RefWorks:RefID:153-omran2020shacl,
author={Omran,Pouya G. and Taylor,Kerry and M 'endez, Sergio Jos 'e Rodr ' iguez and Haller,Armin},
title={Towards SHACL Learning from Knowledge Graphs.},
journal={ISWC (Demos/Industry)},
volume={2721},
pages={94–99},
note={journal: ISWC (Demos/Industry)},
keywords={Knowledge Graph; Used},
year={2020},
}

@conference{RefWorks:RefID:152-rabbani2022shacl,
author={Rabbani,Kashif and Lissandrini,Matteo and Hose,Katja},
editor={ },
title={SHACL and ShEx in the Wild: A Community Survey on Validating Shapes Generation and Adoption},
booktitle={Web Conference 2022},
publisher={ACM},
address={New York, NY, USA},
pages={260–263},
abstract={Knowledge Graphs (KGs) are widely used to represent heterogeneous domain knowledge on the Web and within organizations. Various methods exist to manage KGs and ensure the quality of their data. Among these, the Shapes Constraint Language (SHACL) and the Shapes Expression Language (ShEx) are the two state-of-the-art languages to define validating shapes for KGs. Since the usage of these constraint languages has recently increased, new needs arose. One such need is to enable the efficient generation of these shapes. Yet, since these languages are relatively new, we witness a lack of understanding of how they are effectively employed for existing KGs. Therefore, in this work, we answer How validating shapes are being generated and adopted? Our contribution is threefold. First, we conducted a community survey to analyze the needs of users (both from industry and academia) generating validating shapes. Then, we cross-referenced our results with an extensive survey of the existing tools and their features. Finally, we investigated how existing automatic shape extraction approaches work in practice on real, large KGs. Our analysis shows the need for developing semi-automatic methods that can help users generate shapes from large KGs.},
keywords={Knowledge Graph; Used},
url={https://dl.acm.org/doi/pdf/10.1145/3487553.3524253},
doi={10.1145/3487553.3524253},
publisher={ACM},
year={2022},
}

@article{RefWorks:RefID:151-rabbani2023extraction,
author={Rabbani,Kashif and Lissandrini,Matteo and Hose,Katja},
title={Extraction of Validating Shapes from Very Large Knowledge Graphs},
journal={Proceedings of the VLDB Endowment},
volume={16},
number={5},
pages={1023–1032},
abstract={Knowledge Graphs (KGs) represent heterogeneous domain knowledge on the Web and within organizations. There exist shapes constraint languages to define
validating shapes
to ensure the quality of the data in KGs. Existing techniques to extract validating shapes often fail to extract complete shapes, are not scalable, and are prone to produce spurious shapes. To address these shortcomings, we propose the Quality Shapes Extraction (QSE) approach to extract validating shapes in very large graphs, for which we devise both an exact and an approximate solution. QSE provides information about the reliability of shape constraints by computing their confidence and support within a KG and in doing so allows to identify shapes that are most informative and less likely to be affected by incomplete or incorrect data. To the best of our knowledge, QSE is the first approach to extract a complete set of validating shapes from WikiData. Moreover, QSE provides a 12x reduction in extraction time compared to existing approaches, while managing to filter out up to 93\% of the invalid and spurious shapes, resulting in a reduction of up to 2 orders of magnitude in the number of constraints presented to the user, e.g., from 11,916 to 809 on DBpedia.},
keywords={Knowledge Graph; Used}, issn={2150-8097},
doi={10.14778/3579075.3579078},
year={2023},
url={https://vbn.aau.dk/files/678396868/3579075.3579078.pdf},
}

@article{RefWorks:RefID:148-reiter1978on,
author={Reiter,Raymond},
title={On closed world data bases},
journal={Logic and Data Bases},
pages={55–76},
keywords={Knowledge Graph; Used},
year={1978},
}

@unpublished{RefWorks:RefID:147-bosco2024leading,
author={Bosco,Alex},
title={leading to annual revenue losses of hundreds of thousands of dollars.},
note={I met with Alex Bosco, a Supervisor for Easttown Township, to discuss a recent Zoning Hearing Board (ZHB) decision. The ZHB had granted a waiver to a resident, exempting them from paying the established fee-in-lieu for sidewalk construction.

Our discussion centered on the specifics of this case and its direct implications for the township. We examined the immediate financial cost to the municipality resulting from this single decision and the precedent it might set. Supervisor Bosco provided insight into the legislative and procedural challenges the Board of Supervisors faces when such variances are granted. We explored potential legislative remedies that the township could consider to prevent future fiscal strain and ensure consistent application of the law.

This conversation is a pertinent case study for my research, as it highlights the critical need for clarity and robustness in municipal ordinances. It underscores how an ambiguous or easily challengeable legal framework can lead to ad-hoc decisions that create financial and governance challenges, demonstrating the real-world impact of precisely engineered legislation.},
keywords={Consistency; Law; Used},
year={2024},
}

@unpublished{RefWorks:RefID:146-sanders2024municipal,
author={Sanders,Jeanie},
title={Municipal laws in Pennsylvania Townships, authored by multiple people over time, develop inconsistencies and are incomplete},
note={A telephone interview was conducted with Jeanie Sanders, an administrator at eCode360, the digital repository for numerous Pennsylvania municipal legal codes. The purpose of the communication was twofold: to ascertain the protocols for programmatic access to their legal corpus and to understand their current data validation methodologies.

Ms. Sanders described their existing process for ensuring the integrity of the codes, which relies primarily on manual editorial review and version control. Following this, I presented my doctoral research, which focuses on the application of formal methods to analyze and verify legal frameworks. I outlined my methodology for modeling municipal ordinances as a formal system to programmatically audit the code for internal consistency, completeness, and logical contradictions.

The discussion confirmed the potential utility of such computational tools in the field of legal informatics. Ms. Sanders acknowledged the inherent challenges of maintaining integrity across a large-scale, text-based legal corpus through manual processes alone. This communication was valuable in validating the practical need and real-world applicability for my research into automated legislative analysis and what can be described as 'computational jurisprudence'.},
keywords={Law; Consistency; Used},
year={2024},
}

@unpublished{RefWorks:RefID:145-rau2024municipal,
author={Rau,Andrew},
title={Municipal laws in Pennsylvania Townships, authored by multiple people over time, develop inconsistencies and are incomplete},
note={A personal communication was conducted with Andrew D. Rau, Esq., who serves as the Township Solicitor for Easttown Township. The objective of this discussion was to gain an expert legal perspective on the practical need for my research into the automated verification of municipal codes.

I presented my research on developing a computational tool for analyzing legislative texts to ensure their logical consistency and completeness. Solicitor Rau, drawing upon over two decades of experience in Pennsylvania municipal law, confirmed the inherent limitations of the current multi-stakeholder review process. He affirmed that despite rigorous oversight from Township staff, the solicitor's office, and legislative codifiers, logical lacunae and contradictions can still persist within the legal code.

Solicitor Rau's assessment provides a crucial external validation for the central problem statement of this dissertation. He confirmed that a formal, automated system capable of auditing legal frameworks for structural integrity would represent a significant and highly valuable contribution to the field of municipal governance and law. This conversation underscores the real-world demand for the technological solution my research aims to develop.},
keywords={Law; Consistency; Used},
year={2024},
}

@unpublished{RefWorks:RefID:144-curley2024municipal,
author={Curley,Don},
title={Municipal laws in Pennsylvania Townships, authored by multiple people over time, develop inconsistencies and are incomplete},
note={While my capacity as an Easttown Township Supervisor affords me frequent interaction with Township Manager Don Curley, a specific discussion served as a key point of validation for my doctoral research. This personal communication focused on the systemic challenges encountered in maintaining the logical integrity and referential coherence of the municipal code.

Drawing from his executive perspective as the individual responsible for implementing the Township's ordinances, Mr. Curley confirmed the operational difficulties that arise from ambiguities or contradictions within the legislative text. He articulated the significant administrative burden required to navigate these issues, which can impact staff resources, public clarity, and enforcement consistency.

This discussion was pivotal, as it provided expert confirmation from a senior administrative officer regarding the real-world consequences of imperfect legislative drafting. It affirmed the practical exigency for the development of a computational framework, such as the one proposed in my research, to automate the detection of flaws and enhance the structural quality of municipal law. The conversation effectively bridged the gap between the theoretical underpinnings of my research and the tangible governance challenges faced by municipalities.},
keywords={Used; Law; Consistency},
year={2024},
}

@conference{RefWorks:RefID:143-chia2022relation,
author={Chia,Yew K. and Bing,Lidong and de Lichron,Vladimir and Lee,Kaisheng and Wong,Kam-Fai},
editor={ },
title={Relation Extraction as Open-book Question Answering: Evaluation on a Comprehensive Assessment Dataset},
booktitle={Association for Computational Linguistics: EMNLP 2022},
publisher={Association for Computational Linguistics},
address={Abu Dhabi, United Arab Emirates},
pages={6305–6319},
keywords={Relation Extraction; Used},
publisher={Association for Computational Linguistics},
year={2022},
}

@conference{RefWorks:RefID:142-wu2019enriching,
author={Wu,Shanchan and He,Yifan},
editor={ },
title={Enriching Pre-trained Language Model with Entity Information for Relation Classification},
booktitle={28th ACM International Conference on Information and Knowledge Management (CIKM '19)},
publisher={Association for Computing Machinery},
address={Beijing, China},
pages={2361–2364},
keywords={Relation Extraction; Used},
doi={10.1145/3357384.3358039},
publisher={Association for Computing Machinery},
year={2019},
}

@report{RefWorks:RefID:141-kumar2017survey,
author={Kumar,Shantanu},
title={A Survey of Deep Learning Methods for Relation Extraction},
journal={arXiv},
abstract={Relation Extraction is an important sub-task of Information Extraction which
has the potential of employing deep learning (DL) models with the creation of
large datasets using distant supervision. In this review, we compare the
contributions and pitfalls of the various DL models that have been used for the
task, to help guide the path ahead.},
keywords={Relation Extraction; Used},
url={https://arxiv.org/abs/1705.03645},
doi={10.48550/arxiv.1705.03645},
year={2017},
}

@conference{RefWorks:RefID:140-mintz2009distant,
author={Mintz,Mike and Bills,Steven and Snow,Rion and Jurafsky,Dan},
editor={ },
title={Distant Supervision for Relation Extraction Without Labeled Data},
booktitle={Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP},
publisher={Association for Computational Linguistics},
address={Suntec, Singapore},
pages={1003–1011},
keywords={Relation Extraction; Used},
publisher={Association for Computational Linguistics},
year={2009},
}

@conference{RefWorks:RefID:139-kambhatla2004combining,
author={Kambhatla,Nanda},
editor={ },
title={Combining Lexical, Syntactic, and Semantic Features with Maximum Entropy Models for Extracting Relations},
booktitle={ACL 2004 Workshop on Relation Extraction},
publisher={Association for Computational Linguistics},
address={Barcelona, Spain},
pages={178–181},
keywords={Relation Extraction; Used},
publisher={Association for Computational Linguistics},
year={2004},
}

@conference{RefWorks:RefID:138-agichtein2000snowball,
author={Agichtein,E. and Gravano,L.},
editor={ },
title={Snowball : extracting relations from large plain-text collections},
booktitle={Proceedings of the fifth ACM conference on Digital libraries (DL '00) (pp. 85–94)},
publisher={Association for Computing Machinery},
address={New York, New York, USA},
pages={85–94},
abstract={Text documents often contain valuable structured data that is hidden in regular English sentences. This data is best exploited infavailable as a relational table that we could use for answering precise queries or running data mining tasks. We explore a technique for extracting such tables from document collections that requires only a handful of training examples from users. These examples are used to generate extraction patterns, that in turn result in new tuples being extracted from the document collection. We build on this idea and present our Snowball system. Snowball introduces novel strategies for generating patterns and extracting tuples from plain-text documents. At each iteration of the extraction process, Snowball evaluates the quality of these patterns and tuples without human intervention, and keeps only the most reliable ones for the next iteration. In this paper we also develop a scalable evaluation methodology and metrics for our task, and present a thorough experimental evaluation of Snowball and comparable techniques over a collection of more than 300,000 newspaper documents.},
keywords={Relation Extraction; Used},
doi={https://doi.org/10.1145/336597.336644},
publisher={Association for Computing Machinery},
year={2000},
}

@conference{RefWorks:RefID:137-brin1998extracting,
author={Brin,Sergey},
editor={ },
title={Extracting Patterns and Relations from the World Wide Web},
booktitle={International workshop on the world wide web and databases},
publisher={Springer International Publishing},
pages={172–183},
abstract={The World Wide Web is a vast resource for information. At the same time it is extremely distributed. A particular type of data such as restaurant lists may be scattered across thousands of independent information sources in many different formats. In this paper, we consider the problem of extracting a relation for such a data type from all of these sources automatically. We present a technique which exploits the duality between sets of patterns and relations to grow the target relation starting from a small sample. To test our technique we use it to extract a relation of (author,title) pairs from the World Wide Web.},
keywords={Relation Extraction; Used},
publisher={Springer International Publishing},
year={1998},
}

@article{RefWorks:RefID:136-hearst1992automatic,
author={Hearst,Marti A.},
title={Automatic Acquisition of Hyponyms from Large Text Corpora},
journal={Proceedings of the Fourteenth International Conference on Computational Linguistics, Nantes, Frans},
keywords={Relation Extraction; Used},
year={1992},
}

@article{RefWorks:RefID:135-noy2001ontology,
author={Noy,Natalya F. and McGuinness,Deborah L.},
title={Ontology Development 101 : A Guide to Creating Your First Ontology},
journal={Stanford Knowledge Systems Laboratory Technical Report},
keywords={Ontology; Used},
year={2001},
}

@article{RefWorks:RefID:134-etzioni2008acm,
author={Etzioni,Oren and Banko,Michele and Soderland,Stephen and Weld,Daniel S.},
title={ACM: Digital Library: Communications of the ACM},
journal={Communications of the ACM},
volume={51},
number={12},
pages={68–74},
abstract={Say you want to select a quiet, centrally located Manhattan hotel. Google returns an overwhelming seven million results in response to the query "new york city hotels." Or, say you are trying to assemble a program committee for an annual conference composed of researchers who have published at the conference in previous years, and to balance it geographically. While today's Web search engines identify potentially relevant documents, you are forced to sift through a long list of URLs, scan each document to identify any pertinent bits of information, and assemble the extracted findings before you can solve your problem.

Over the coming decade, Web searching will increasingly transcend keyword queries in favor of systems that automate the tedious and error-prone task of sifting through documents. Moreover, we will build systems that fuse relevant pieces of information into a coherent overview, thus reducing from hours to minutes the time required to perform complex tasks.

Information extraction (IE)a venerable technology that maps natural-language text into structured relational data offers a promising avenue toward this goal. Although extracting data from text is inherently challenging, given the ambiguous and idiosyncratic nature of natural language, substantial progress has been made over the last few decades.

This article surveys a range of IE methods, but we highlight Open Information Extraction,3,4 where in the identities of the relations to be extracted are unknown and the billions of documents found on the Web necessitate highly scalable processing.},
keywords={Information Extraction; Used},
year={2008},
url={https://dl.acm.org/doi/fullHtml/10.1145/1409360.1409378},
}

@article{RefWorks:RefID:132-luo2018attentionbased,
author={Luo,Ling and Yang,Zhihao and Yang,Pei and Zhang,Yin and Wang,Lei and Lin,Hongfei and Wang,Jian},
title={An attention-based BiLSTM-CRF approach to document-level chemical named entity recognition},
journal={Bioinformatics},
volume={34},
number={8},
pages={1381–1388},
abstract={In biomedical research, chemical is an important class of entities, and chemical named entity recognition (NER) is an important task in the field of biomedical information extraction. However, most popular chemical NER methods are based on traditional machine learning and their performances are heavily dependent on the feature engineering. Moreover, these methods are sentence-level ones which have the tagging inconsistency problem.In this paper, we propose a neural network approach, i.e. attention-based bidirectional Long Short-Term Memory with a conditional random field layer (Att-BiLSTM-CRF), to document-level chemical NER. The approach leverages document-level global information obtained by attention mechanism to enforce tagging consistency across multiple instances of the same token in a document. It achieves better performances with little feature engineering than other state-of-the-art methods on the BioCreative IV chemical compound and drug name recognition (CHEMDNER) corpus and the BioCreative V chemical-disease relation (CDR) task corpus (the F-scores of 91.14 and 92.57\%, respectively).Data and code are available at https://github.com/lingluodlut/Att-ChemdNER.Supplementary data are available at Bioinformatics online.},
keywords={Named Entity Recognition; Used}, issn={1367-4803},
doi={10.1093/bioinformatics/btx761},
year={2018},
url={https://doi.org/10.1093/bioinformatics/btx761},
}

@conference{RefWorks:RefID:131-lample2016neural,
author={Lample,Guillaume and Ballesteros,Miguel and Subramanian,Sandeep and Kawakami,Kazuya and Dyer,Chris},
editor={ },
title={Neural Architectures for Named Entity Recognition},
booktitle={NAACL-HLT},
publisher={arXiv},
pages={260–270},
abstract={State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
keywords={Computer Science - Computation and Language; Named Entity Recognition; Used},
url={http://arxiv.org/abs/1603.01360},
publisher={arXiv},
year={2016},
}

@conference{RefWorks:RefID:130-lin2017multichannel,
author={Lin,Bill Y. and Xu,Frank and Luo,Zhiyi and Zhu,Kenny},
editor={Derczynski,Leon and Xu,Wei and Ritter,Alan and Baldwin,Tim},
title={Multi-channel BiLSTM-CRF Model for Emerging Named Entity Recognition in Social Media},
booktitle={3rd Workshop on Noisy User-generated Text},
publisher={Association for Computational Linguistics},
address={Copenhagen, Denmark},
pages={160–165},
abstract={In this paper, we present our multi-channel neural architecture for recognizing emerging named entity in social media messages, which we applied in the Novel and Emerging Named Entity Recognition shared task at the EMNLP 2017 Workshop on Noisy User-generated Text (W-NUT). We propose a novel approach, which incorporates comprehensive word representations with multi-channel information and Conditional Random Fields (CRF) into a traditional Bidirectional Long Short-Term Memory (BiLSTM) neural network without using any additional hand-craft features such as gazetteers. In comparison with other systems participating in the shared task, our system won the 2nd place.},
keywords={Named Entity Recognition; Used},
url={https://aclanthology.org/W17-4421/},
doi={10.18653/v1/W17-4421},
publisher={Association for Computational Linguistics},
year={2017},
}

@conference{RefWorks:RefID:128-lafferty2001conditional,
author={Lafferty,John and Mccallum,Andrew and Pereira,Fernando},
editor={ },
title={Conditional random fields: Probabilistic models for segmenting and labeling sequence data},
booktitle={ICML},
pages={282–289},
keywords={Named Entity Recognition; Used},
year={2001},
}

@conference{RefWorks:RefID:127-grishman1996messageunderstanding,
author={Grishman,Ralph and Sundheim,Beth},
editor={ },
title={Message-Understanding Conference-6: A Brief History},
booktitle={The 16th international conference on computational linguistics},
note={COLING 1996 volume 1: The 16th international conference on computational linguistics},
keywords={Named Entity Recognition; Used},
year={1996},
}

@article{RefWorks:RefID:126-nadeau2007survey,
author={Nadeau,David and Sekine,Satoshi},
title={A survey of named entity recognition and classification},
journal={Lingvisticae Investigationes},
volume={30},
number={1},
pages={3–26},
abstract={This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress.},
keywords={Named Entity Recognition; Used}, issn={0378-4169},
doi={10.1075/li.30.1.03nad},
year={2007},
url={https://www.proquest.com/docview/3073805790},
}

@conference{RefWorks:RefID:125-kalamkar2022named,
author={Kalamkar,Prathamesh and Agarwal,Astha and Tiwari,Aman and Gupta,Smita and Karn,Saurabh and Raghavan,Vivek},
editor={ },
title={Named Entity Recognition in Indian court judgments},
booktitle={Natural Legal Language Processing Workshop 2022},
publisher={Association for Computational Linguistics},
pages={184–193},
abstract={Identification of named entities from legal texts is an essential building
block for developing other legal Artificial Intelligence applications. Named
Entities in legal texts are slightly different and more fine-grained than
commonly used named entities like Person, Organization, Location etc. In this
paper, we introduce a new corpus of 46545 annotated legal named entities mapped
to 14 legal entity types. The Baseline model for extracting legal named
entities from judgment text is also developed.},
keywords={Named Entity Recognition; Law; Used},
url={https://aclanthology.org/2022.nllp-1.pdf#page=199},
publisher={Association for Computational Linguistics},
year={2022},
}

@conference{RefWorks:RefID:124-au2022ener,
author={Au,Ting W. T. and Cox,Ingemar J. and Lampos,Vasileios},
editor={ },
title={E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text},
booktitle={Natural Legal Language Processing Workshop},
publisher={Association for Computational Linguistics},
pages={246–255},
abstract={Identifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models requires an annotated data set, which can be a time-consuming labour-intensive task. Nevertheless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a significant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a publicly available legal NER data set, called E-NER, based on legal company filings available from the US Securities and Exchange Commission's EDGAR data set. Training a number of different NER algorithms on the general English CoNLL-2003 corpus but testing on our test collection confirmed significant degradations in accuracy, as measured by the F1-score, of between 29.4\% and 60.4\%, compared to training and testing on the E-NER collection.},
keywords={Computer Science - Computation and Language; Named Entity Recognition; Law; Used},
url={http://arxiv.org/abs/2212.09306},
publisher={Association for Computational Linguistics},
year={2022},
}

@conference{RefWorks:RefID:122-kolluru2020imojie,
author={Kolluru,Keshav and Aggarwal,Samarth and Rathore,Vipul and Chakrabarti,Soumen},
editor={Jurafsky,Dan and Chai,Joyce and Schluter,Natalie and Tetreault,Joel},
title={IMoJIE: Iterative Memory-Based Joint Open Information Extraction},
booktitle={58th Annual Meeting of the Association for Computational Linguistics},
publisher={Association for Computational Linguistics},
address={Online},
pages={5871–5886},
abstract={While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et. al. 18). Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMoJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMoJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMoJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.},
keywords={Information Extraction; Used},
url={https://aclanthology.org/2020.acl-main.521/},
doi={10.18653/v1/2020.acl-main.521},
publisher={Association for Computational Linguistics},
year={2020},
}

@article{RefWorks:RefID:121-zhong2024comprehensive,
author={Zhong,Lingfeng and Wu,Jia and Li,Qian and Peng,Hao and Wu,Xindong},
title={A Comprehensive Survey on Automatic Knowledge Graph Construction},
journal={ACM computing surveys},
volume={56},
number={4},
pages={1–62},
abstract={Automatic knowledge graph construction aims at manufacturing structured human knowledge. To this end, much effort has historically been spent extracting informative fact patterns from different data sources. However, more recently, research interest has shifted to acquiring conceptualized structured knowledge beyond informative data. In addition, researchers have also been exploring new ways of handling sophisticated construction tasks in diversified scenarios. Thus, there is a demand for a systematic review of paradigms to organize knowledge structures beyond data-level mentions. To meet this demand, we comprehensively survey more than 300 methods to summarize the latest developments in knowledge graph construction. A knowledge graph is built in three steps: knowledge acquisition, knowledge refinement, and knowledge evolution. The processes of knowledge acquisition are reviewed in detail, including obtaining entities with fine-grained types and their conceptual linkages to knowledge graphs; resolving coreferences; and extracting entity relationships in complex scenarios. The survey covers models for knowledge refinement, including knowledge graph completion, and knowledge fusion. Methods to handle knowledge evolution are also systematically presented, including condition knowledge acquisition, condition knowledge graph completion, and knowledge dynamic. We present the paradigms to compare the distinction among these methods along the axis of the data environment, motivation, and architecture. Additionally, we also provide briefs on accessible resources that can help readers to develop practical knowledge graph systems. The survey concludes with discussions on the challenges and possible directions for future exploration.},
keywords={Information Extraction; Knowledge Graph; Used; Survey}, issn={0360-0300},
doi={10.1145/3618295},
year={2024},
url={https://dl.acm.org/doi/10.1145/3618295},
}

@book{RefWorks:RefID:120-fensel2020knowledge,
author={Fensel,Dieter and Şimşek,Umutcan and Angele,Kevin and Huaman,Elwin and Kärle,Elias and Panasiuk,Oleksandra and Toma,Ioan and Umbrich,Jürgen and Wahler,Alexander},
title={Knowledge Graphs : Methodology, Tools and Selected Use Cases},
abstract={This book describes methods and tools that empower information providers to build and maintain knowledge graphs, including those for manual, semi-automatic, and automatic construction; implementation; and validation and verification of semantic annotations and their integration into knowledge graphs. It also presents lifecycle-based approaches for semi-automatic and automatic curation of these graphs, such as approaches for assessment, error correction, and enrichment of knowledge graphs with other static and dynamic resources.Chapter 1 defines knowledge graphs, focusing on the impact of various approaches rather than mathematical precision. Chapter 2 details how knowledge graphs are built, implemented, maintained, and deployed. Chapter 3 then introduces relevant application layers that can be built on top of such knowledge graphs, and explains how inference can be used to define views on such graphs, making it a useful resource for open and service-oriented dialog systems. Chapter 4 discusses applications of knowledge graph technologies for e-tourism and use cases for other verticals. Lastly, Chapter 5 provides a summary and sketches directions for future work. The additional appendix introduces an abstract syntax and semantics for domain specifications that are used to adapt schema.org to specific domains and tasks.To illustrate the practical use of the approaches presented, the book discusses several pilots with a focus on conversational interfaces, describing how to exploit knowledge graphs for e-marketing and e-commerce. It is intended for advanced professionals and researchers requiring a brief introduction to knowledge graphs and their implementation.                                   },
publisher={Springer International Publishing},
address={Cham},
edition={1},
note={It is not available online. So, I ordered it from the library.},
keywords={Knowledge Graph; Used},
isbn={9783030374389},
url={https://library.biblioboard.com/viewer/df6f48f2-c37f-11ea-bb63-0ae0aa0d175d},
doi={10.1007/978-3-030-37439-6},
year={2020},
translator={Anonymous },
}

@article{RefWorks:RefID:118-ji2022survey,
author={Ji,Shaoxiong and Pan,Shirui and Cambria,Erik and Marttinen,Pekka and Yu,Philip S.},
title={A Survey on Knowledge Graphs: Representation, Acquisition, and Applications},
journal={IEEE transaction on neural networks and learning systems},
volume={33},
number={2},
pages={494–514},
abstract={Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledge-aware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods, path inference, and logical rule reasoning are reviewed. We further explore several emerging topics, including metarelational learning, commonsense reasoning, and temporal knowledge graphs. To facilitate future research on knowledge graphs, we also provide a curated collection of data sets and open-source libraries on different tasks. In the end, we have a thorough outlook on several promising research directions.},
keywords={Knowledge Graph; Used; Survey}, issn={2162-237X},
doi={10.1109/TNNLS.2021.3070843},
pmid={33900922},
year={2022},
url={https://ieeexplore.ieee.org/document/9416312},
}

@online{RefWorks:RefID:117-spornyjsonld,
author={Sporny,Manu and Longley,Dave and Kellogg,Gregg and Lanthaler,Markus and Champin,Pierre-Antoine and Lindström,Niklas},
title={JSON-LD 1.1},
journal={W3C},
year={2025},
abstract={JSON is a useful data serialization and messaging format. This specification defines JSON-LD 1.1, a JSON-based format to serialize Linked Data. The syntax is designed to easily integrate into deployed systems that already use JSON, and provides a smooth upgrade path from JSON to JSON-LD. It is primarily intended to be a way to use Linked Data in Web-based programming environments, to build interoperable Web services, and to store Linked Data in JSON-based storage engines.

This specification describes a superset of the features defined in JSON-LD 1.0 [JSON-LD10] and, except where noted, documents created using the 1.0 version of this specification remain compatible with JSON-LD 1.1.},
keywords={Knowledge Graph; Used},
url={https://www.w3.org/TR/json-ld11/},
year={2025},
}

@conference{RefWorks:RefID:116-shaham2022scrolls,
author={Shaham,Uri and Segal,Elad and Ivgi,Maor and Efrat,Avia and Yoran,Ori and Haviv,Adi and Gupta,Ankit and Xiong,Wenhan and Geva,Mor and Berant,Jonathan and Levy,Omer},
editor={ },
title={SCROLLS: Standardized CompaRison Over Long Language Sequences},
booktitle={Conference on Empirical Methods in Natural Language Processing},
publisher={Association for Computational Linguistics},
pages={12007–12021},
abstract={NLP benchmarks have largely focused on short texts, such as sentences and
paragraphs, even though long texts comprise a considerable amount of natural
language in the wild. We introduce SCROLLS, a suite of tasks that require
reasoning over long texts. We examine existing long-text datasets, and handpick
ones where the text is naturally long, while prioritizing tasks that involve
synthesizing information across the input. SCROLLS contains summarization,
question answering, and natural language inference tasks, covering multiple
domains, including literature, science, business, and entertainment. Initial
baselines, including Longformer Encoder-Decoder, indicate that there is ample
room for improvement on SCROLLS. We make all datasets available in a unified
text-to-text format and host a live leaderboard to facilitate research on model
architecture and pretraining methods.},
keywords={Document; LLM; Used},
url={https://arxiv.org/abs/2201.03533},
doi={10.48550/arXiv.2201.03533},
publisher={Association for Computational Linguistics},
year={2022},
}

@conference{RefWorks:RefID:115-ratner2022parallel,
author={Ratner,Nir and Levine,Yoav and Belinkov,Yonatan and Ram,Ori and Magar,Inbal and Abend,Omri and Karpas,Ehud and Shashua,Amnon and Leyton-Brown,Kevin and Shoham,Yoav},
editor={ },
title={Parallel Context Windows for Large Language Models},
booktitle={The 61st Annual Meeting of the Association for Computational Linguistics},
publisher={Association for Computational Linguistics},
pages={6383–6402},
abstract={When applied to processing long text, Large Language Models (LLMs) are
limited by their context window. Existing efforts to address this limitation
involve training specialized architectures, and cannot be easily applied to
off-the-shelf LLMs. We present Parallel Context Windows (PCW), a method that
alleviates the context window restriction for any off-the-shelf LLM without
further training. The key to the approach is to carve a long context into
chunks (``windows''), restrict the attention mechanism to apply only within
each window, and re-use the positional embeddings across the windows. Our main
results test the PCW approach on in-context learning with models that range in
size between 750 million and 178 billion parameters, and show substantial
improvements for tasks with diverse input and output spaces. We show additional
benefits in other settings where long context windows may be beneficial:
multi-hop questions and retrieval-augmented question answering with multiple
retrieved documents. Our results highlight Parallel Context Windows as a
promising method for applying off-the-shelf LLMs in a range of settings that
require long text sequences. We make our code publicly available at
https://github.com/ai21labs/parallel-context-windows.},
keywords={LLM; Used},
url={https://arxiv.org/abs/2212.10947},
doi={10.48550/arxiv.2212.10947},
publisher={Association for Computational Linguistics},
year={2022},
}

@conference{RefWorks:RefID:114-fernandes2018graph,
author={Fernandes,Diogo and Bernardino,Jorge},
editor={ },
title={Graph Databases Comparison: AllegroGraph, ArangoDB, InfiniteGraph, Neo4J, and OrientDB},
booktitle={7th International Conference on Data Science, Technology and Applications (DATA 2018)},
pages={373–380},
abstract={Graph databases are a very powerful solution for storing and searching for data designed for data rich in
relationships, such as Facebook and Twitter. With data multiplication and data type diversity there has been
a need to create new storage and analysis platforms that structure irregular data with a flexible schema,
maintaining a high level of performance and ensuring data scalability effectively, which is a problem that
relational databases cannot handle. In this paper, we analyse the most popular graph databases:
AllegroGraph, ArangoDB, InfiniteGraph, Neo4J and OrientDB. We study the most important features for a
complete and effective application, such as flexible schema, query language, sharding and scalability.},
keywords={Knowledge Graph; Used},
url={https://doi.org/10.5220/0006910203730380},
doi={10.5220/0006910203730380},
year={2018},
}

@online{RefWorks:RefID:112-hartig2025sparql,
author={Hartig,Olaf and Seaborne,Andy and Taelman,Ruben and Williams,Williams and Tanon,Thomas},
title={SPARQL 1.2 Query Language},
journal={W3C},
year={2025},
keywords={Knowledge Graph; Used},
url={https://www.w3.org/TR/sparql12-query/},
year={2025},
}

@conference{RefWorks:RefID:111-kumar2013querying,
author={Kumar,Naveen and Kumar,Suresh},
editor={ },
title={Querying RDF and OWL data source using SPARQL},
booktitle={Fourth International Conference on Computing, Communications and Networking Technologies (ICCCNT)},
publisher={IEEE},
pages={1–6},
abstract={The Semantic web is the extension of WWW, “web of document” that provide a support for “web of data” it gives an easier way to find, share, reuse and combine information. The semantic web can be best known as the web of linked data that enables people to create data stores on the web, build vocabularies, and write rules for handling data. It is based on machine-readable information and builds on XML technology's capability to define customized tagging schemes and RDF's (Resource Description Framework) flexible approach to representing data. The key challenge for many semantic web application is to access RDF and OWL data source, as a solution to this challenge, SPARQL, the w3c Recommendation for an RDF query language, supports querying of multiple RDF graphs and OWL data. In this paper we propose a framework for querying RDF data and OWL data using SPARQL. We perform querying the data using “TWINKLE” and “PROTEGE” tool and we also provide an experimental result of improving query performance by optimizing the query.},
keywords={Resource description framework; OWL; Query processing; Ontologies; Optimization; XML; SPARQL; Query Optimization; Semantic web; RDF; Knowledge Graph; Used},
url={https://ieeexplore.ieee.org/abstract/document/6726698},
doi={10.1109/ICCCNT.2013.6726698},
publisher={IEEE},
year={2013},
}

@book{RefWorks:RefID:110-hitzler2009foundations,
author={Hitzler,Pascal and Krotzsch,Markus and Rudolph,Sebastian},
title={Foundations of Semantic Web Technologies},
abstract={Thoroughly covering basic introductions and intuitions, technical details, and formal foundations, this text focuses on the established foundations in this area that have become relatively stable over time. It presents the latest developments in Semantic Web standards, including RDF, RDF Schema, OWL 2, RIF, and SPARQL. It also explores formal semantics, OWL querying, the relationship between rules and OWL, and ontology engineering and applications.},
publisher={Chapman and Hall/CRC},
address={New York},
pages={456},
edition={1st},
keywords={Knowledge Graph; Used},
isbn={9780429143472},
url={https://www.taylorfrancis.com/books/mono/10.1201/9781420090512/foundations-semantic-web-technologies-pascal-hitzler-markus-krotzsch-sebastian-rudolph},
year={2009},
translator={Anonymous },
}

@online{RefWorks:RefID:109-2025rdf,
title={RDF 1.2 Primer},
journal={W3C},
year={2025},
abstract={Pierre-Antoine Champin
Niklas Lindström},
keywords={Knowledge Graph; Used},
url={https://www.w3.org/TR/rdf12-primer/},
year={2025},
}

@article{RefWorks:RefID:108-ehrlinger2016definition,
author={Ehrlinger,Lisa and W{ "o}{ ss},Wolfram},
title={Towards a definition of knowledge graphs},
journal={SEMANTiCS (Posters, Demos, SuCCESS)},
volume={48},
number={1-4},
pages={2},
keywords={Knowledge Graph; Used},
year={2016},
}

@article{RefWorks:RefID:107-benjira2025automated,
author={Benjira,Wissal and Atigui,Faten and Bucher,Bénédicte and Grim-Yefsah,Malika and Travers,Nicolas},
title={Automated mapping between SDG indicators and open data: An LLM-augmented knowledge graph approach},
journal={Data \& knowledge engineering},
volume={156},
pages={102405},
abstract={Meeting the Sustainable Development Goals (SDGs) presents a large-scale challenge for all countries. SDGs established by the United Nations provide a comprehensive framework for addressing global issues. To monitor progress towards these goals, we need to develop key performance indicators and integrate and analyze heterogeneous datasets. The definition of these indicators requires the use of existing data and metadata. However, the diversity of data sources and formats raises major issues in terms of structuring and integration. Despite the abundance of open data and metadata, its exploitation remains limited, leaving untapped potential for guiding urban policies towards sustainability. Thus, this paper introduces a novel approach for SDG indicator computation, leveraging the capabilities of Large Language Models (LLMs) and Knowledge Graphs (KGs). We propose a method that combines rule-based filtering with LLM-powered schema mapping to establish semantic correspondences between diverse data sources and SDG indicators, including disaggregation. Our approach integrates these mappings into a KG, which enables indicator computation by querying graph’s topology. We evaluate our method through a case study focusing on the SDG Indicator 11.7.1 about accessibility of public open spaces. Our experimental results show significant improvements in accuracy, precision, recall, and F1-score compared to traditional schema mapping techniques.},
keywords={Knowledge Graph; LLM; Used}, issn={0169-023X},
doi={10.1016/j.datak.2024.102405},
year={2025},
url={https://dx.doi.org/10.1016/j.datak.2024.102405},
}

@article{RefWorks:RefID:106-tay2023efficient,
author={Tay,Yi and Dehghani,Mostafa and Bahri,Dara and Metzler,Donald},
title={Efficient Transformers: A Survey},
journal={ACM computing surveys},
volume={55},
number={6},
pages={1–28},
abstract={Transformer model architectures have garnered immense interest lately due to their effectiveness across a range of domains like language, vision, and reinforcement learning. In the field of natural language processing for example, Transformers have become an indispensable staple in the modern deep learning stack. Recently, a dizzying number of “X-former” models have been proposed—Reformer, Linformer, Performer, Longformer, to name a few—which improve upon the original Transformer architecture, many of which make improvements around computational and memory efficiency. With the aim of helping the avid researcher navigate this flurry, this article characterizes a large and thoughtful selection of recent efficiency-flavored “X-former” models, providing an organized and comprehensive overview of existing work and models across multiple domains.},
keywords={LLM; Used}, issn={0360-0300},
doi={10.1145/3530811},
year={2023},
url={https://dl.acm.org/doi/10.1145/3530811},
}

@conference{RefWorks:RefID:105-chen2024dense,
author={Chen,Tong and Wang,Hongwei and Chen,Sihao and Yu,Wenhao and Ma,Kaixin and Zhao,Xinran and Zhang,Hongming and Yu,Dong},
editor={ },
title={Dense X Retrieval: What Retrieval Granularity Should We Use?},
booktitle={2024 Conference on Empirical Methods in Natural Language Processing},
publisher={Association for Computational Linguistics},
pages={15159–15177},
abstract={Dense retrieval has become a prominent method to obtain relevant context or
world knowledge in open-domain NLP tasks. When we use a learned dense retriever
on a retrieval corpus at inference time, an often-overlooked design choice is
the retrieval unit in which the corpus is indexed, e.g. document, passage, or
sentence. We discover that the retrieval unit choice significantly impacts the
performance of both retrieval and downstream tasks. Distinct from the typical
approach of using passages or sentences, we introduce a novel retrieval unit,
proposition, for dense retrieval. Propositions are defined as atomic
expressions within text, each encapsulating a distinct factoid and presented in
a concise, self-contained natural language format. We conduct an empirical
comparison of different retrieval granularity. Our experiments reveal that
indexing a corpus by fine-grained units such as propositions significantly
outperforms passage-level units in retrieval tasks. Moreover, constructing
prompts with fine-grained retrieved units for retrieval-augmented language
models improves the performance of downstream QA tasks given a specific
computation budget.},
keywords={LLM; Used},
url={https://arxiv.org/abs/2312.06648},
doi={10.48550/arxiv.2312.06648},
publisher={Association for Computational Linguistics},
year={2024},
}

@report{RefWorks:RefID:104-qu2024semantic,
author={Qu,Renyi and Tu,Ruixuan and Bao,Forrest},
title={Is Semantic Chunking Worth the Computational Cost?},
journal={arXiv},
abstract={Recent advances in Retrieval-Augmented Generation (RAG) systems have popularized semantic chunking, which aims to improve retrieval performance by dividing documents into semantically coherent segments. Despite its growing adoption, the actual benefits over simpler fixed-size chunking, where documents are split into consecutive, fixed-size segments, remain unclear. This study systematically evaluates the effectiveness of semantic chunking using three common retrieval-related tasks: document retrieval, evidence retrieval, and retrieval-based answer generation. The results show that the computational costs associated with semantic chunking are not justified by consistent performance gains. These findings challenge the previous assumptions about semantic chunking and highlight the need for more efficient chunking strategies in RAG systems.},
keywords={Computer Science - Computation and Language; Computer Science - Information Retrieval; LLM; Used},
url={http://arxiv.org/abs/2410.13070},
year={2024},
}

@report{RefWorks:RefID:103-schmidt2024tokenization,
author={Schmidt,Craig W. and Reddy,Varshini and Zhang,Haoran and Alameddine,Alec and Uzan,Omri and Pinter,Yuval and Tanner,Chris},
title={Tokenization Is More Than Compression},
journal={arXiv},
abstract={Tokenization is a foundational step in natural language processing (NLP) tasks, bridging raw text and language models. Existing tokenization approaches like Byte-Pair Encoding (BPE) originate from the field of data compression, and it has been suggested that the effectiveness of BPE stems from its ability to condense text into a relatively small number of tokens. We test the hypothesis that fewer tokens lead to better downstream performance by introducing PathPiece, a new tokenizer that segments a document's text into the minimum number of tokens for a given vocabulary. Through extensive experimentation we find this hypothesis not to be the case, casting doubt on the understanding of the reasons for effective tokenization. To examine which other factors play a role, we evaluate design decisions across all three phases of tokenization: pre-tokenization, vocabulary construction, and segmentation, offering new insights into the design of effective tokenizers. Specifically, we illustrate the importance of pre-tokenization and the benefits of using BPE to initialize vocabulary construction. We train 64 language models with varying tokenization, ranging in size from 350M to 2.4B parameters, all of which are made publicly available.},
keywords={Computer Science - Computation and Language; Computer Science - Artificial Intelligence; LLM; Used},
url={http://arxiv.org/abs/2402.18376},
year={2024},
}

@article{RefWorks:RefID:102-hogan2021knowledge,
author={Hogan,Aidan and Blomqvist,Eva and Cochez,Michael and D'amato,Claudia and De Melo,Gerard and Gutierrez,Claudio and Kirrane,Sabrina and Gayo,José E. L. and Navigli,Roberto and Neumaier,Sebastian and Ngomo,Axel-Cyrille N. and Polleres,Axel and Rashid,Sabbir M. and Rula,Anisa and Schmelzeisen,Lukas and Sequeda,Juan and Staab,Steffen and Zimmermann,Antoine},
title={Knowledge Graphs},
journal={ACM Computing Surveys},
volume={54},
number={4},
pages={1–37},
abstract={In this article, we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models, as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs.},
keywords={Knowledge Graph; Used}, issn={0360-0300},
doi={10.1145/3447772},
year={2021},
url={https://www.proquest.com/docview/2671351403},
}

@report{RefWorks:RefID:101-zhao2023survey,
author={Zhao,Wayne X. and Zhou,Kun and Li,Junyi and Tang,Tianyi and Wang,Xiaolei and Hou,Yupeng and Min,Yingqian and Zhang,Beichen and Zhang,Junjie, et al},
title={A survey of large language models},
journal={arXiv},
volume={1},
number={2},
abstract={Language is essentially a complex, intricate system of human expressions
governed by grammatical rules. It poses a significant challenge to develop
capable AI algorithms for comprehending and grasping a language. As a major
approach, language modeling has been widely studied for language understanding
and generation in the past two decades, evolving from statistical language
models to neural language models. Recently, pre-trained language models (PLMs)
have been proposed by pre-training Transformer models over large-scale corpora,
showing strong capabilities in solving various NLP tasks. Since researchers
have found that model scaling can lead to performance improvement, they further
study the scaling effect by increasing the model size to an even larger size.
Interestingly, when the parameter scale exceeds a certain level, these enlarged
language models not only achieve a significant performance improvement but also
show some special abilities that are not present in small-scale language
models. To discriminate the difference in parameter scale, the research
community has coined the term large language models (LLM) for the PLMs of
significant size. Recently, the research on LLMs has been largely advanced by
both academia and industry, and a remarkable progress is the launch of ChatGPT,
which has attracted widespread attention from society. The technical evolution
of LLMs has been making an important impact on the entire AI community, which
would revolutionize the way how we develop and use AI algorithms. In this
survey, we review the recent advances of LLMs by introducing the background,
key findings, and mainstream techniques. In particular, we focus on four major
aspects of LLMs, namely pre-training, adaptation tuning, utilization, and
capacity evaluation. Besides, we also summarize the available resources for
developing LLMs and discuss the remaining issues for future directions.},
keywords={LLM; Used; Survey},
url={https://arxiv.org/abs/2303.18223},
doi={10.48550/arXiv.2303.18223},
year={2023},
}

@report{RefWorks:RefID:100-kaplan2020scaling,
author={Kaplan,Jared and McCandlish,Sam and Henighan,Tom and Brown,Tom B. and Chess,Benjamin and Child,Rewon and Gray,Scott and Radford,Alec and Wu,Jeffrey and Amodei,Dario},
title={Scaling Laws for Neural Language Models},
journal={arXiv},
abstract={We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.},
keywords={Computer Science - Machine Learning; Statistics - Machine Learning; LLM; Used},
url={http://arxiv.org/abs/2001.08361},
year={2020},
}

@report{RefWorks:RefID:99-liu2025comprehensive,
author={Liu,Jiaheng and Zhu,Dawei and Bai,Zhiqi and He,Yancheng and Liao,Huanxuan and Que,Haoran and Wang,Zekun and Zhang,Chenchen and Zhang,Ge, et al},
title={A Comprehensive Survey on Long Context Language Modeling},
journal={arXiv},
abstract={Efficient processing of long contexts has been a persistent pursuit in Natural Language Processing. With the growing number of long documents, dialogues, and other textual data, it is important to develop Long Context Language Models (LCLMs) that can process and analyze extensive inputs in an effective and efficient way. In this paper, we present a comprehensive survey on recent advances in long-context modeling for large language models. Our survey is structured around three key aspects: how to obtain effective and efficient LCLMs, how to train and deploy LCLMs efficiently, and how to evaluate and analyze LCLMs comprehensively. For the first aspect, we discuss data strategies, architectural designs, and workflow approaches oriented with long context processing. For the second aspect, we provide a detailed examination of the infrastructure required for LCLM training and inference. For the third aspect, we present evaluation paradigms for long-context comprehension and long-form generation, as well as behavioral analysis and mechanism interpretability of LCLMs. Beyond these three key aspects, we thoroughly explore the diverse application scenarios where existing LCLMs have been deployed and outline promising future development directions. This survey provides an up-to-date review of the literature on long-context LLMs, which we wish to serve as a valuable resource for both researchers and engineers. An associated GitHub repository collecting the latest papers and repos is available at: https://github.com/LCLM-Horizon/A-Comprehensive-Survey-For-Long-Context-Language-Modeling},
keywords={Computer Science - Computation and Language; Computer Science - Machine Learning; LLM; Used},
url={http://arxiv.org/abs/2503.17407},
year={2025},
}

@conference{RefWorks:RefID:97-cong2024research,
author={Cong,Yu},
editor={ },
title={Research for Enhancing Processing and Computational Efficiency in LLM},
booktitle={Proceedings of the 2024 2nd International Conference on Image, Algorithms and Artificial Intelligence (ICIAAI 2024)},
publisher={Atlantis Press},
pages={970–980},
abstract={In the context of current technological development, large language models (LLMs) have become a core component of artificial intelligence. This report provides an in-depth discussion of various advanced strategies and techniques to improve the processing and computational efficiency of LLMs. First, the report goes through a detailed analysis of automatic...},
keywords={LLM; Used},
url={https://www.atlantis-press.com/proceedings/iciaai-24/126004157},
doi={10.2991/978-94-6463-540-9_97},
publisher={Atlantis Press},
year={2024},
}

@conference{RefWorks:RefID:96-rzepka2023expert,
author={Rzepka,Rafal and Muraji,Shinji and Obayashi,Akihiko},
editor={ },
title={Expert Evaluation of Export Control-Related Question Answering Capabilities of LLMs},
booktitle={IEEE Asia-Pacific Conference on Computer Science and Data Engineering (CSDE)},
publisher={IEEE},
pages={1–6},
note={ID: cdi ieee primary 10487735},
abstract={In this paper we introduce evaluation experiments performed by an expert to assess Large Language Models ability to answer questions related to export control in Japanese language. We compare outputs of two popular models, namely ChatGPT and GPT-4, and measure their accuracy in predicting intention of the question and label of the answer. Prediction results indicate that both models were better in guessing question intention but failed to recognize what type of an answer would be most probable. Furthermore, expert evaluation of outputs generated by both models show that most of the answers contain mistakes which can mislead users asking a dialog system for an expertise. We analyze these outputs and enumerate problems to be tackled in the future.},
keywords={Chatbots; Computer science; LLM; Used},
isbn={9798350341072},
doi={10.1109/CSDE59766.2023.10487735},
publisher={IEEE},
year={2023},
}

@report{RefWorks:RefID:95-grattafiori2024llama,
author={Grattafiori,Aaron and Dubey,Abhimanyu and Jauhri,Abhinav and Pandey,Abhinav and Kadian,Abhishek and Al-Dahle,Ahmad and Letman,Aiesha and Mathur,Akhil and Schelten,Alan, et al},
title={The Llama 3 Herd of Models},
journal={arXiv},
abstract={Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
keywords={Computer Science - Artificial Intelligence; Computer Science - Computation and Language; Computer Science - Computer Vision and Pattern Recognition; LLM; Used},
url={http://arxiv.org/abs/2407.21783},
year={2024},
}

@article{RefWorks:RefID:94-caruccio2024claude,
author={Caruccio,Loredana and Cirillo,Stefano and Polese,Giuseppe and Solimando,Giandomenico and Sundaramurthy,Shanmugam and Tortora,Genoveffa},
title={Claude 2.0 large language model: Tackling a real-world classification problem with a new iterative prompt engineering approach},
journal={Intelligent systems with applications},
volume={21},
pages={200336},
abstract={In the last year, Large Language Models (LLMs) have transformed the way of tackling problems, opening up new perspectives in various works and research fields, due to their ability to generate and understand human languages. In this regard, the recent release of Claude 2.0 has contributed to the processing of more complex prompts. In this scenario, the goal of this paper is to evaluate the effectiveness of Claude 2.0 in a specific classification task. In particular, we considered the Forest cover-type problem, concerning the prediction of a cover-type value according to the geospatial characterization of target worldwide areas. To this end, we propose a novel iterative prompt template engineering approach, which integrates files by exploiting prompts and evaluates the quality of responses provided by the LLM. Moreover, we conducted several comparative analyses to evaluate the effectiveness of Claude 2.0 with respect to online and batch learning models. The results demonstrated that, although some online and batch models performed better than Claude 2.0, the new iterative prompt engineering approach improved the quality of responses, leading to better performance with increases ranging from 14\% to 32\% in terms of accuracy, precision, recall, and F1-score.},
keywords={LLM; Used}, issn={2667-3053},
doi={10.1016/j.iswa.2024.200336},
year={2024},
url={https://dx.doi.org/10.1016/j.iswa.2024.200336},
}

@report{RefWorks:RefID:93-team2024gemini,
author={Team,Gemini and Anil,Rohan and Borgeaud,Sebastian and Alayrac,Jean-Baptiste and Yu,Jiahui and Soricut,Radu and Schalkwyk,Johan and Dai,Andrew M. and Hauth,Anja, et al},
title={Gemini: A Family of Highly Capable Multimodal Models},
journal={Google Deep Mind},
note={I tried uploading the PDF but it would not upload. It is in my Reference file as 2312.11805v4 (1).pdf.},
abstract={This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.},
keywords={Computer Science - Computation and Language; Computer Science - Artificial Intelligence; Computer Science - Computer Vision and Pattern Recognition; LLM; Used},
url={http://arxiv.org/abs/2312.11805},
year={2024},
}

@report{RefWorks:RefID:92-gao2023examining,
author={Gao,Kaiyuan and He,Sunan and He,Zhenyu and Lin,Jiacheng and Pei,QiZhi and Shao,Jie and Zhang,Wei},
title={Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models},
journal={arXiv},
abstract={Generative pre-trained transformer (GPT) models have revolutionized the field of natural language processing (NLP) with remarkable performance in various tasks and also extend their power to multimodal domains. Despite their success, large GPT models like GPT-4 face inherent limitations such as considerable size, high computational requirements, complex deployment processes, and closed development loops. These constraints restrict their widespread adoption and raise concerns regarding their responsible development and usage. The need for user-friendly, relatively small, and open-sourced alternative GPT models arises from the desire to overcome these limitations while retaining high performance. In this survey paper, we provide an examination of alternative open-sourced models of large GPTs, focusing on user-friendly and relatively small models that facilitate easier deployment and accessibility. Through this extensive survey, we aim to equip researchers, practitioners, and enthusiasts with a thorough understanding of user-friendly and relatively small open-sourced models of large GPTs, their current state, challenges, and future research directions, inspiring the development of more efficient, accessible, and versatile GPT models that cater to the broader scientific community and advance the field of general artificial intelligence. The source contents are continuously updating in https://github.com/GPT-Alternatives/gpt\_alternatives.},
keywords={Computer Science - Artificial Intelligence; Computer Science - Computation and Language; LLM; Used},
url={http://arxiv.org/abs/2308.14149},
year={2023},
}

@report{RefWorks:RefID:90-turner2024introduction,
author={Turner,Richard E.},
title={An Introduction to Transformers},
journal={arXiv},
abstract={The transformer is a neural network component that can be used to learn useful representations of sequences or sets of data-points. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture. We will not discuss training as this is rather standard. We assume that the reader is familiar with fundamental topics in machine learning including multi-layer perceptrons, linear transformations, softmax functions and basic probability.},
keywords={Computer Science - Machine Learning; Computer Science - Artificial Intelligence; Transformer; Used},
url={http://arxiv.org/abs/2304.10557},
year={2024},
}

@report{RefWorks:RefID:89-badshah2024quantifying,
author={Badshah,Sher and Sajjad,Hassan},
title={Quantifying the Capabilities of LLMs across Scale and Precision},
journal={arXiv},
abstract={Scale is often attributed as one of the factors that cause an increase in the performance of LLMs, resulting in models with billion and trillion parameters. One of the limitations of such large models is the high computational requirements that limit their usage, deployment, and debugging in resource-constrained scenarios. Two commonly used alternatives to bypass these limitations are to use the smaller versions of LLMs (e.g. Llama 7B instead of Llama 70B) and lower the memory requirements by using quantization. While these approaches effectively address the limitation of resources, their impact on model performance needs thorough examination. In this study, we perform a comprehensive evaluation to investigate the effect of model scale and quantization on the performance. We experiment with two major families of open-source instruct models ranging from 7 billion to 70 billion parameters. Our extensive zero-shot experiments across various tasks including natural language understanding, reasoning, misinformation detection, and hallucination reveal that larger models generally outperform their smaller counterparts, suggesting that scale remains an important factor in enhancing performance. We found that larger models show exceptional resilience to precision reduction and can maintain high accuracy even at 4-bit quantization for numerous tasks and they serve as a better solution than using smaller models at high precision under similar memory requirements.},
keywords={Computer Science - Machine Learning; Computer Science - Artificial Intelligence; Computer Science - Computation and Language; LLM; Used},
url={http://arxiv.org/abs/2405.03146},
year={2024},
}

@report{RefWorks:RefID:88-ye2024llmda,
author={Ye,Junjie and Xu,Nuo and Wang,Yikun and Zhou,Jie and Zhang,Qi and Gui,Tao and Huang,Xuanjing},
title={LLM-DA: Data Augmentation via Large Language Models for Few-Shot Named Entity Recognition},
journal={arXiv},
abstract={Despite the impressive capabilities of large language models (LLMs), their performance on information extraction tasks is still not entirely satisfactory. However, their remarkable rewriting capabilities and extensive world knowledge offer valuable insights to improve these tasks. In this paper, we propose LLM-DA, a novel data augmentation technique based on LLMs for the few-shot NER task. To overcome the limitations of existing data augmentation methods that compromise semantic integrity and address the uncertainty inherent in LLM-generated text, we leverage the distinctive characteristics of the NER task by augmenting the original data at both the contextual and entity levels. Our approach involves employing 14 contextual rewriting strategies, designing entity replacements of the same type, and incorporating noise injection to enhance robustness. Extensive experiments demonstrate the effectiveness of our approach in enhancing NER model performance with limited data. Furthermore, additional analyses provide further evidence supporting the assertion that the quality of the data we generate surpasses that of other existing methods.},
keywords={Computer Science - Computation and Language; LLM; Named Entity Recognition; Used},
url={http://arxiv.org/abs/2402.14568},
year={2024},
}

@report{RefWorks:RefID:87-wang2023gptner,
author={Wang,Shuhe and Sun,Xiaofei and Li,Xiaoya and Ouyang,Rongbin and Wu,Fei and Zhang,Tianwei and Li,Jiwei and Wang,Guoyin},
title={GPT-NER: Named Entity Recognition via Large Language Models},
journal={arXiv},
abstract={Despite the fact that large-scale Language Models (LLM) have achieved SOTA
performances on a variety of NLP tasks, its performance on NER is still
significantly below supervised baselines. This is due to the gap between the
two tasks the NER and LLMs: the former is a sequence labeling task in nature
while the latter is a text-generation model.
In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the
gap by transforming the sequence labeling task to a generation task that can be
easily adapted by LLMs e.g., the task of finding location entities in the input
text "Columbus is a city" is transformed to generate the text sequence
"@@Columbus\#\# is a city", where special tokens @@\#\# marks the entity to
extract. To efficiently address the "hallucination" issue of LLMs, where LLMs
have a strong inclination to over-confidently label NULL inputs as entities, we
propose a self-verification strategy by prompting LLMs to ask itself whether
the extracted entities belong to a labeled entity tag.
We conduct experiments on five widely adopted NER datasets, and GPT-NER
achieves comparable performances to fully supervised baselines, which is the
first time as far as we are concerned. More importantly, we find that GPT-NER
exhibits a greater ability in the low-resource and few-shot setups, when the
amount of training data is extremely scarce, GPT-NER performs significantly
better than supervised models. This demonstrates the capabilities of GPT-NER in
real-world NER applications where the number of labeled examples is limited.},
keywords={Named Entity Recognition; LLM; Used},
url={https://arxiv.org/abs/2304.10428},
doi={10.48550/arxiv.2304.10428},
year={2023},
}

@online{RefWorks:RefID:84-edwards2024exponential,
author={Edwards,Benj},
title={Exponential growth brews 1 million AI models on Hugging Face},
journal={Ars Technica},
year={2025},
keywords={LLM; Used},
url={https://arstechnica.com/information-technology/2024/09/ai-hosting-platform-surpasses-1-million-models-for-the-first-time/},
year={2025},
}

@article{RefWorks:RefID:81-vaswani2017attention,
author={Vaswani,Ashish and Shazeer,Noam and Brain,Google and Parmar,Niki and Uszkoreit,Jakob and Jones,Llion and Gomez,Aidan N. and Kaiser,Łukasz},
title={Attention Is All You Need},
journal={Advances in Neural Information Processing Systems},
abstract={The dominant sequence transduction models are based on complex recurrent or
convolutional neural networks that include an encoder and a decoder. The best
performing models also connect the encoder and decoder through an attention
mechanism. We propose a new simple network architecture, the Transformer,
based solely on attention mechanisms, dispensing with recurrence and convolutions
entirely. Experiments on two machine translation tasks show these models to
be superior in quality while being more parallelizable and requiring significantly
less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including
ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,
our model establishes a new single-model state-of-the-art BLEU score of 41.8 after
training for 3.5 days on eight GPUs, a small fraction of the training costs of the
best models from the literature. We show that the Transformer generalizes well to
other tasks by applying it successfully to English constituency parsing both with
large and limited training data.},
keywords={Used; LLM},
year={2017},
}

@thesis{RefWorks:RefID:78-minsky1974framework,
author={Minsky,Marvin},
title={A Framework for Representing Knowledge},
abstract={This is a partial theory of thinking, combining a number of classical and modern concepts from psychology, linguistics, and AI. Whenever one encounters a new situation (or makes a substantial change in one's viewpoint) he selects from memory a structure called a frame, a remembered framework to be adopted to fit reality by changing details as necessary. A frame is a data-structure for representing a stereotyped situation, like being in a certain kind of living room, or going to a child's birthday party. Attached to each frame are several kinds of information. Some of this information is about how to use the frame. Some is about what one can expect to happen next. Some is about what to do if these expectations are not confirmed. The "top levels" of a frame are fixed, and represent things that are always true about the supposed situation. The lower levels have many "alota" that must be filled by specific instances or data. Collections of related frames are linked together into frame-systems. The effects of important actions are mirrored by transformations between the frames of a system. These are used to make certain kinds of calculations economical, to represent changes of emphasis and attention and to account for effectiveness of "imagery". In Vision, the different frames of a system describe the scene from different viewpoints, and the transformations between one frame and another represent the effects of moving from place to place. Other kinds of frame-systems can represent actions, cause-effect relations, or changes in conceptual viewpoint. The paper applies the frame-system idea also to problems of linguistic understanding: memory, acquisition and retrieval of knowledge, and a variety of ways to reason by analogy and jump to conclusions based on partial similarity matching.},
keywords={Knowledge Graph; Ontology; Used},
url={http://hdl.handle.net/1721.1/6089},
year={1974},
}

@article{RefWorks:RefID:77-tauqeer2022automated,
author={Tauqeer,Amar and Kurteva,Anelia and Chhetri,Tek R. and Ahmeti,Albin and Fensel,Anna},
title={Automated GDPR Contract Compliance Verification Using Knowledge Graphs},
journal={Information (Basel)},
volume={13},
number={10},
pages={447},
abstract={In the past few years, the main research efforts regarding General Data Protection Regulation (GDPR)-compliant data sharing have been focused primarily on informed consent (one of the six GDPR lawful bases for data processing). In cases such as Business-to-Business (B2B) and Business-to-Consumer (B2C) data sharing, when consent might not be enough, many small and medium enterprises (SMEs) still depend on contracts—a GDPR basis that is often overlooked due to its complexity. The contract’s lifecycle comprises many stages (e.g., drafting, negotiation, and signing) that must be executed in compliance with GDPR. Despite the active research efforts on digital contracts, contract-based GDPR compliance and challenges such as contract interoperability have not been sufficiently elaborated on yet. Since knowledge graphs and ontologies provide interoperability and support knowledge discovery, we propose and develop a knowledge graph-based tool for GDPR contract compliance verification (CCV). It binds GDPR’s legal basis to data sharing contracts. In addition, we conducted a performance evaluation in terms of execution time and test cases to validate CCV’s correctness in determining the overhead and applicability of the proposed tool in smart city and insurance application scenarios. The evaluation results and the correctness of the CCV tool demonstrate the tool’s practicability for deployment in the real world with minimum overhead.},
keywords={Document; Knowledge Graph; Law; Named Entity Recognition; Ontology; Used}, issn={2078-2489},
doi={10.3390/info13100447},
year={2022},
url={https://www.proquest.com/docview/2728484478},
}

@report{RefWorks:RefID:76-dhani2021similar,
author={Dhani,Jaspreet S. and Bhatt,Ruchika and Ganesan,Balaji and Sirohi,Parikshet and Bhatnagar,Vasudha},
title={Similar Cases Recommendation using Legal Knowledge Graphs},
journal={arXiv},
abstract={A legal knowledge graph constructed from court cases, judgments, laws and
other legal documents can enable a number of applications like question
answering, document similarity, and search. While the use of knowledge graphs
for distant supervision in NLP tasks is well researched, using knowledge graphs
for applications like case similarity presents challenges. In this work, we
describe our solution for predicting similar cases in Indian court judgements.
We present our results and also discuss the impact of large language models on
this task.},
keywords={Document; Knowledge Graph; Named Entity Recognition; Used},
url={https://arxiv.org/abs/2107.04771},
doi={10.48550/arxiv.2107.04771},
year={2021},
}

@report{RefWorks:RefID:68-beth2018bills,
author={Beth,Richard S.},
title={How bills amend statutes},
journal={Congressional Research Service},
volume={RS20617},
note={Explains some of the issues that can arise when a new law is in conflict with existing laws.},
keywords={Law; Used},
url={https://purl.fdlp.gov/GPO/gpo126602},
year={2018},
}

@conference{RefWorks:RefID:64-2022lexglue,
author={Ilias Chalkidis and Abhik Jana and Dirk Hartung and Michael Bommarito and Ion Androutsopoulos and Daniel Katz and Nikolaos Aletras},
editor={ },
title={LexGLUE: A Benchmark Dataset for Legal Language Understanding in English},
booktitle={60th Annual Meeting of the Association for Computational Linguistics},
publisher={Association for Computational Linguistics},
abstract={Laws and their interpretations, legal arguments
and agreements are typically expressed in writing, leading to the production of vast corpora
of legal text. Their analysis, which is at the
center of legal practice, becomes increasingly
elaborate as these collections grow in size.
Natural language understanding (NLU) technologies can be a valuable tool to support legal practitioners in these endeavors. Their usefulness, however, largely depends on whether
current state-of-the-art models can generalize
across various tasks in the legal domain. To
answer this currently open question, we introduce the Legal General Language Understanding Evaluation (LexGLUE) benchmark, a collection of datasets for evaluating model performance across a diverse set of legal NLU tasks
in a standardized way. We also provide an
evaluation and analysis of several generic and
legal-oriented models demonstrating that the
latter consistently offer performance improvements across multiple tasks.},
keywords={Document; Law; Named Entity Recognition; Used},
url={https://aclanthology.org/2022.acl-long.297.pdf},
doi={10.18653/v1/2022.acl-long.297},
publisher={Association for Computational Linguistics},
year={2022},
}

@report{RefWorks:RefID:62-malik2022semantic,
author={Malik,Vijit and Rishabh Sanjay and Guha,Shouvik K. and Hazarika,Angshuman and Nigam,Shubham and Bhattacharya,Arnab and Modi,Ashutosh},
title={Semantic Segmentation of Legal Documents via Rhetorical Roles},
journal={arXiv},
abstract={Legal documents are unstructured, use legal jargon, and have considerable length, making them difficult to process automatically via conventional text processing techniques. A legal document processing system would benefit substantially if the documents could be segmented into coherent information units. This paper proposes a new corpus of legal documents annotated (with the help of legal experts) with a set of 13 semantically coherent units labels (referred to as Rhetorical Roles), e.g., facts, arguments, statute, issue, precedent, ruling, and ratio. We perform a thorough analysis of the corpus and the annotations. For automatically segmenting the legal documents, we experiment with the task of rhetorical role prediction: given a document, predict the text segments corresponding to various roles. Using the created corpus, we experiment extensively with various deep learning-based baseline models for the task. Further, we develop a multitask learning (MTL) based deep model with document rhetorical role label shift as an auxiliary task for segmenting a legal document. The proposed model shows superior performance over the existing models. We also experiment with model performance in the case of domain transfer and model distillation techniques to see the model performance in limited data conditions.},
keywords={Document; Law; Used},
url={https://www.proquest.com/docview/2607084336},
year={2022},
}

@conference{RefWorks:RefID:57-carbonell2020named,
author={Carbonell,Manuel and Riba,Pau and Villegas,Mauricio and Fornes,Alicia and Llados,Josep},
editor={ },
title={Named Entity Recognition and Relation Extraction with Graph Neural Networks in Semi Structured Documents},
booktitle={International Conference on Pattern Recognition},
publisher={IEEE},
address={Piscataway},
pages={9622–9627},
abstract={The use of administrative documents to communicate and leave record of business information requires of methods able to automatically extract and understand the content from such documents in a robust and efficient way. In addition, the semi-structured nature of these reports is specially suited for the use of graph-based representations which are flexible enough to adapt to the deformations from the different document templates. Moreover, Graph Neural Networks provide the proper methodology to learn relations among the data elements in these documents. In this work we study the use of Graph Neural Network architectures to tackle the problem of entity recognition and relation extraction in semi-structured documents. Our approach achieves state of the art results in the three tasks involved in the process. Additionally, the experimentation with two datasets of different nature demonstrates the good generalization ability of our approach.},
keywords={GNN; Document; Named Entity Recognition; Used},
url={https://ieeexplore.ieee.org/document/9412669},
doi={10.1109/ICPR48806.2021.9412669},
publisher={IEEE},
year={2020},
}

@inbook{RefWorks:RefID:54-rossi2016inconsistent,
author={Rossi,Matthias},
title={Inconsistent Legislation},
booktitle ={Legisprudence library},
publisher={Springer International Publishing},
address={Cham},
pages={189–208},
abstract={In a number of rulings, the German Federal Constitutional Court has called on the legislature to show consistency, and has declared null and void statutes which it considered to be inconsistent. This “principle of consistency” helps to strengthen the rationality of the law, at least as a reflex, but also to fortify the position of the Federal Constitutional Court within the structure of the constitutional bodies. It focuses on the self-obligation of the legislature: It is to be tied to a selected regulatory concept to such a degree that any deviation is to be classified as contradictory, and hence at the same time as unconstitutional. The paper portrays the development of the constitutional court case-law on the “principle of consistency”, and then goes on to criticise it vehemently: Firstly, a “principle of consistency” confuses the relative standard of equality rights with the absolute standard of freedom rights. Secondly, it causes the law to transform from an object into a yardstick for constitutional review, thereby turning it into a standard reviewing itself. Thirdly, the “principle of consistency” helps to radicalise the legal system because political consistency is now required where practical concordance was previously called for. However inconsistent proportionate legislation may at times be, consistent legislation tends to be disproportionate. Fourthly, it remains unclear how the regulatory or protective concept of a statute can be determined which is to serve as a standard for the law as a whole. Fifthly, and finally, the separation of powers between the legislature and the Federal Constitutional Court stands opposed to the idea of a principle of consistency. Democratic legislation is always also inconsistent legislation. A principle of consistency may therefore only be understood as an item on the political and legislative wishlist, but not as a principle underlying the rule of law.},
keywords={Consistency; Law; Used},
isbn={3319332155},
url={http://link.springer.com/10.1007/978-3-319-33217-8_8},
doi={10.1007/978-3-319-33217-8_8},
year={2016},
translator={Anonymous },
}

@article{RefWorks:RefID:53-duck-mayr2022explaining,
author={Duck-Mayr,JBrandon},
title={Explaining legal inconsistency},
journal={Journal of theoretical politics},
volume={34},
number={1},
pages={107–126},
abstract={Judges, scholars, and commentators decry inconsistent areas of judicially created policy. This could hurt courts’ policy making efficacy, so why do judges allow it to happen? I show judicially-created policy can become inconsistent when judges explain rules in more abstract terms than they decide cases. To do so, I expand standard case-space models of judicial decision making to account for relationships between specific facts and broader doctrinal dimensions. This model of judicial decision making as a process of multi-step reasoning reveals that preference aggregation in such a context can lead to inconsistent collegial rules. I also outline a class of preference configurations on collegial courts (i.e., multi-member courts) in which this problem cannot arise. These results have implications for several areas of inquiry in judicial politics such as models of principal-agent relationships in judicial hierarchies and empirical research utilizing case facts as predictor variables.},
keywords={Consistency; Law; Used}, issn={0951-6298},
doi={10.1177/09516298211061159},
year={2022},
url={https://journals.sagepub.com/doi/full/10.1177/09516298211061159},
}

@article{RefWorks:RefID:52-donelson2019legal,
author={Donelson,Raff},
title={Legal Inconsistencies },
journal={Tulsa Law Review},
volume={55},
number={1},
pages={16–44},
abstract={It is a familiar thought from the rule of law literature and from everyday life that
legal norms within a given jurisdiction ought to be consistent. However, little work has
been done to explain this demand. This Article develops a theory of legal inconsistencies,
both what they are and why legal systems ought to avoid them. In addition to contributing
to a theoretical discussion of legal inconsistency, the Article also articulates a remedy
under American law for those harmed by inconsistencies. The Article contends that legal
inconsistencies violate Due Process.},
keywords={Consistency; Law; Used},
year={2019},
url={https://digitalcommons.law.utulsa.edu/tlr/vol55/iss1/14},
}

@conference{RefWorks:RefID:51-chen2021explicitly,
author={Chen,Pei and Ding,Haibo and Araki,Jun and Huang,Ruihong},
editor={Zong,Chengqing and Xia,Fei and Li,Wenjie and Navigli,Roberto},
title={Explicitly Capturing Relations between Entity Mentions via Graph Neural Networks for Domain-specific Named Entity Recognition},
booktitle={59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing},
publisher={Association for Computational Linguistics},
volume={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
pages={735–742},
abstract={Named entity recognition (NER) is well studied for the general domain, and recent systems have achieved human-level performance for identifying common entity types. However, the NER performance is still moderate for specialized domains that tend to feature complicated contexts and jargonistic entity types. To address these challenges, we propose explicitly connecting entity mentions based on both global coreference relations and local dependency relations for building better entity mention representations. In our experiments, we incorporate entity mention relations by Graph Neural Networks and show that our system noticeably improves the NER performance on two datasets from different domains. We further show that the proposed lightweight system can effectively elevate the NER performance to a higher level even when only a tiny amount of labeled data is available, which is desirable for domain-specific NER.},
keywords={GNN; Used},
url={https://aclanthology.org/2021.acl-short.93},
doi={10.18653/v1/2021.acl-short.93},
publisher={Association for Computational Linguistics},
year={2021},
}

@article{RefWorks:RefID:49-wang2024graph,
author={Wang,Kunze and Ding,Yihao and Han,Soyeon C.},
title={Graph neural networks for text classification: a survey},
journal={The Artificial intelligence review},
volume={57},
number={8},
pages={190},
abstract={Text Classification is the most essential and fundamental problem in Natural Language Processing. While numerous recent text classification models applied the sequential deep learning technique, graph neural network-based models can directly deal with complex structured text data and exploit global information. Many real text classification applications can be naturally cast into a graph, which captures words, documents, and corpus global features. In this survey, we bring the coverage of methods up to 2023, including corpus-level and document-level graph neural networks. We discuss each of these methods in detail, dealing with the graph construction mechanisms and the graph-based learning process. As well as the technological survey, we look at issues behind and future directions addressed in text classification using graph neural networks. We also cover datasets, evaluation metrics, and experiment design and present a summary of published performance on the publicly available benchmarks. Note that we present a comprehensive comparison between different techniques and identify the pros and cons of various evaluation metrics in this survey.},
keywords={GNN; Survey; Used}, issn={1573-7462},
doi={10.1007/s10462-024-10808-0},
year={2024},
url={https://link.springer.com/article/10.1007/s10462-024-10808-0},
}

@report{RefWorks:RefID:48-feng2024comprehensive,
author={Feng,ZhengZhao and Wang,Rui and Wang,TianXing and Song,Mingli and Wu,Sai and He,Shuibing},
title={A Comprehensive Survey of Dynamic Graph Neural Networks: Models, Frameworks, Benchmarks, Experiments and Challenges},
journal={arXiv},
abstract={Dynamic Graph Neural Networks (GNNs) combine temporal information with GNNs
to capture structural, temporal, and contextual relationships in dynamic graphs
simultaneously, leading to enhanced performance in various applications. As the
demand for dynamic GNNs continues to grow, numerous models and frameworks have
emerged to cater to different application needs. There is a pressing need for a
comprehensive survey that evaluates the performance, strengths, and limitations
of various approaches in this domain. This paper aims to fill this gap by
offering a thorough comparative analysis and experimental evaluation of dynamic
GNNs. It covers 81 dynamic GNN models with a novel taxonomy, 12 dynamic GNN
training frameworks, and commonly used benchmarks. We also conduct experimental
results from testing representative nine dynamic GNN models and three
frameworks on six standard graph datasets. Evaluation metrics focus on
convergence accuracy, training efficiency, and GPU memory usage, enabling a
thorough comparison of performance across various models and frameworks. From
the analysis and evaluation results, we identify key challenges and offer
principles for future research to enhance the design of models and frameworks
in the dynamic GNNs field.},
keywords={GNN; Survey; Used},
url={https://arxiv.org/abs/2405.00476},
doi={10.48550/arxiv.2405.00476},
year={2024},
}

@article{RefWorks:RefID:47-scarselli2009graph,
author={Scarselli,F. and Gori,M. and Ah Chung Tsoi and Hagenbuchner,M. and Monfardini,G.},
title={The Graph Neural Network Model},
journal={IEEE transaction on neural networks and learning systems},
volume={20},
number={1},
pages={61–80},
abstract={Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IR m that maps a graph G and one of its nodes n into an m -dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.},
keywords={GNN; Used}, issn={1045-9227},
doi={10.1109/TNN.2008.2005605},
pmid={19068426},
year={2009},
url={https://ieeexplore.ieee.org/document/4700287},
}

@conference{RefWorks:RefID:46-li2021cachebased,
author={Li,Haoyang and Chen,Lei},
editor={ },
title={Cache-based GNN System for Dynamic Graphs},
booktitle={30th ACM International Conference on Information \& Knowledge Management},
publisher={ACM},
address={New York, NY, USA},
location={Virtual Event, Queensland, Australia},
pages={937–946},
abstract={Graph Neural Networks (GNNs) have achieved great success in downstream applications due to their ability to learn node representations. However, in many applications, graphs are not static. They often evolve with changes, such as the adjustment of node attributes or graph structures. These changes require node representations to be updated accordingly. It is non-trivial to apply current GNNs to update node representations in a scalable manner. Recent research proposes two types of solutions. The first solution, sampling neighbors for the influenced nodes, requires expensive processing for each node. The second solution, reducing the repeated computations by merging the shared neighbors, cannot speed up the updating process if the influenced nodes do not share neighbors. Most importantly, the above solutions ignore the hidden representations obtained in the previous times that can be reused to accelerate the representation updating. In this paper, we propose a general cache-based GNN system to accelerate the representation updating. Specifically, we cache a set of hidden representations obtained in the previous times, and then reuse them in the next time. To identify valuable hidden representations, we first estimate the number of hidden representations and their combinations that can be reused. Secondly, we formulate the k-assembler problem that selects k representations to maximize the saved time for the next updating process. Experiments on three real-world graphs show that the cache-based GNN system can significantly speed up the representation updating for various GNNs.},
keywords={GNN; Knowledge Graph; Used},
isbn={9781450384469},
url={https://doi.org/10.1145/3459637.3482237},
doi={10.1145/3459637.3482237},
publisher={ACM},
year={2021},
}

@article{RefWorks:RefID:45-moens2001innovative,
author={Moens,Marie F.},
title={Innovative techniques for legal text retrieval},
journal={Artificial intelligence and law},
volume={9},
number={1},
pages={29–57},
keywords={Document; Law; Used}, issn={0924-8463},
doi={10.1023/A:1011297104922},
year={2001},
url={https://www.proquest.com/docview/216171011/abstract/},
}

@article{RefWorks:RefID:44-wang2014short,
author={Wang and Guo},
title={A Short Analysis of Discourse Coherence},
journal={Journal of Language Teaching and Research},
volume={5},
number={2},
pages={460},
abstract={As an essential element of discourse, coherence has been the focus of study for several decades. Previous researches mainly view discourse coherence as a static product and explore it on linguistic level. However, it is also a dynamic process and can be achieved by the cooperation made by the discourse producer and receiver based on their mutual understanding. It involves both linguistic and non-linguistic factors. In this article, the author reviews previous researches on discourse coherence and presents the nature of discourse coherence from cognitive perspective, aiming at giving an insight into discourse comprehension and teaching. Index Terms--discourse coherence, cognitive, cohesion},
keywords={Coherence; Used}, issn={1798-4769},
doi={10.4304/jltr.5.2.460-465},
year={2014},
url={https://www.proquest.com/docview/1507307366/abstract/},
}

@article{RefWorks:RefID:35-verma2024journey,
author={Verma,Umika},
title={A journey from AI to Gen-AI},
journal={Spectrum of Emerging Sciences},
volume={4},
number={1},
pages={74–78},
abstract={The history of artificial intelligence (AI), from its conception to the creation of general AI (Gen-AI), is a fascinating story of human inventiveness, technical growth, and philosophical research. This article examines the historical milestones, major inventions, and transformational concepts that have influenced AI's trajectory. Beginning with early symbolic AI and rule-based systems, it investigates the shift to machine learning, highlighting discoveries in neural networks and deep learning that transformed disciplines such as computer vision and natural language processing. The introduction of generative models, such as GANs and VAEs, resulted in a considerable increase in AI capabilities, paving the path for Gen-AI. Unlike narrow AI, Gen-AI strives to imitate human-like intelligence and adaptability across a wide range of jobs, bringing serious ethical and philosophical concerns. This essay also looks at the current state of Gen-AI, its problems, and possible applications in healthcare, education, finance, and other areas. It finishes by picturing a future in which human-machine collaboration and ethical AI development are prioritized, highlighting the need of continual learning and responsible innovation.},
keywords={LLM; Used}, issn={2583-2603},
doi={10.55878/SES2024-4-1-14},
year={2024},
}

@inbook{RefWorks:RefID:30-guo2023joint,
author={Guo,Bokai and Feng,Chong and Liu,Fang and Li,Xinyan and Wang,Xiaomei},
title={Joint Contrastive Learning for Factual Consistency Evaluation of Cross-Lingual Abstract Summarization},
booktitle ={Machine Translation},
publisher={Springer Nature Singapore},
address={Singapore},
volume={1922},
pages={116–127},
abstract={Current summarization models tend to generate erroneous or irrelevant summaries, i.e., factual inconsistency, which undoubtedly hinders the real-world application of summarization models. The difficulty in language alignment makes factual inconsistency in cross-lingual summarization (CLS) more common and factual consistency checking more challenging. Research on factual consistency has paid little attention to CLS due to the above difficulties, focusing mainly on monolingual summarization (MS). In this paper, we investigate the cross-lingual domain and propose a weakly supervised factual consistency evaluation model for CLS. In particular, we automatically synthesize large-scale datasets by a series of rule-based text transformations and manually annotate the test and validation sets. In addition, we also train the model jointly with contrastive learning to enhance the model’s ability to recognize factual errors. The experimental results on the manually annotated test set show that our model can effectively identify the consistency between the summaries and the source documents and outperform the baseline models.},
keywords={Consistency; Document; Used},
isbn={9789819978939},
url={https://library.biblioboard.com/viewer/c3c10bad-7923-11ee-a305-0a9b31268bf5},
doi={10.1007/978-981-99-7894-6_11},
year={2023},
translator={Anonymous },
}

@article{RefWorks:RefID:29-umar2024advances,
author={Umar,Muhammad A. and Lano,Kevin},
title={Advances in automated support for requirements engineering: a systematic literature review},
journal={Requirements engineering},
volume={29},
number={2},
pages={177–207},
abstract={Requirements Engineering (RE) has undergone several transitions over the years, from traditional methods to agile approaches emphasising increased automation. In many software development projects, requirements are expressed in natural language and embedded within large volumes of text documents. At the same time, RE activities aim to define software systems' functionalities and constraints. However, manually executing these tasks is time-consuming and prone to errors. Numerous research efforts have proposed tools and technologies for automating RE activities to address this challenge, which are documented in published works. This review aims to examine empirical evidence on automated RE and analyse its impact on the RE sub-domain and software development. To achieve our goal, we conducted a Systematic Literature Review (SLR) following established guidelines for conducting SLRs. We aimed to identify, aggregate, and analyse papers on automated RE published between 1996 and 2022. We outlined the output of the support tool, the RE phase covered, levels of automation, development approach, and evaluation approaches. We identified 85 papers that discussed automated RE from various perspectives and methodologies. The results of this review demonstrate the significance of automated RE for the software development community, which has the potential to shorten development cycles and reduce associated costs. The support tools primarily assist in generating UML models (44.7\%) and other activities such as omission of steps, consistency checking, and requirement validation. The analysis phase of RE is the most widely automated phase, with 49.53\% of automated tools developed for this purpose. Natural language processing technologies, particularly POS tagging and Parser, are widely employed in developing these support tools. Controlled experimental methods are the most frequently used (48.2\%) for evaluating automated RE tools, while user studies are the least employed evaluation method (8.2\%). This paper contributes to the existing body of knowledge by providing an updated overview of the research literature, enabling a better understanding of trends and state-of-the-art practices in automated RE for researchers and practitioners. It also paves the way for future research directions in automated requirements engineering.},
keywords={Consistency; Coherence; Completeness; Used}, issn={0947-3602},
doi={10.1007/s00766-023-00411-0},
year={2024},
url={https://link.springer.com/article/10.1007/s00766-023-00411-0},
}

@conference{RefWorks:RefID:28-yang2024fizz,
author={Yang,Joonho and Yoon,Seunghyun and Kim,Byeongjeong and Lee,Hwanhee},
editor={Al-Onaizan,Yaser and Bansal,Mohit and Chen,Yun-Nung},
title={FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document},
booktitle={2024 Conference on Empirical Methods in Natural Language Processing},
publisher={Association for Computational Linguistics},
address={Miami, Florida, USA},
pages={30–45},
abstract={Through the advent of pre-trained language models, there have been notable
advancements in abstractive summarization systems. Simultaneously, a
considerable number of novel methods for evaluating factual consistency in
abstractive summarization systems has been developed. But these evaluation
approaches incorporate substantial limitations, especially on refinement and
interpretability. In this work, we propose highly effective and interpretable
factual inconsistency detection method metric Factual Inconsistency Detection
by Zoom-in Summary and Zoom-out Document for abstractive summarization systems
that is based on fine-grained atomic facts decomposition. Moreover, we align
atomic facts decomposed from the summary with the source document through
adaptive granularity expansion. These atomic facts represent a more
fine-grained unit of information, facilitating detailed understanding and
interpretability of the summary's factual inconsistency. Experimental results
demonstrate that our proposed factual consistency checking system significantly
outperforms existing systems.},
keywords={Consistency; Document; Used},
url={https://arxiv.org/abs/2404.11184},
doi={10.18653/v1/2024.emnlp-main.3},
publisher={Association for Computational Linguistics},
year={2024},
}

@article{RefWorks:RefID:27-tröls2022instant,
author={Tröls,Michael A. and Marchezan,Luciano and Mashkoor,Atif and Egyed,Alexander},
title={Instant and global consistency checking during collaborative engineering},
journal={Software and systems modeling},
volume={21},
number={6},
pages={2489–2515},
abstract={Engineering projects involve a variety of artifacts such as requirements, design, or source code. These artifacts, many of which tend to be interdependent, are often manipulated concurrently. To keep artifacts consistent, engineers must continuously consider their work in relation to the work of multiple other engineers. Traditional consistency checking approaches reason efficiently over artifact changes and their consistency implications. However, they do so solely within the boundaries of specific tools and their specific artifacts (e.g., consistency checking between different UML models). This makes it difficult to examine the consistency between different types of artifacts (e.g., consistency checking between UML models and the source code). Global consistency checking can help addressing this problem. However, it usually requires a disruptive and time-consuming merging process for artifacts. This article presents a novel, cloud-based approach to global consistency checking in a multi-developer/-tool engineering environment. It allows for global consistency checking across all artifacts that engineers work on concurrently. Moreover, it reasons over artifact changes immediately after the change happened, while keeping the (memory/CPU) cost of consistency checking minimal. The feasibility and scalability of our approach were demonstrated by a prototype implementation and through an empirical validation.},
keywords={Consistency; Used}, issn={1619-1366},
doi={10.1007/s10270-022-00984-4},
year={2022},
url={https://link.springer.com/article/10.1007/s10270-022-00984-4},
}

@conference{RefWorks:RefID:26-egyed2006instant,
author={Egyed,Alexander},
editor={ },
title={Instant consistency checking for the UML},
booktitle={Proceedings of the 28th international conference on Software engineering},
publisher={ACM},
address={New York, NY, USA},
pages={381–390},
abstract={Inconsistencies in design models should be detected immediately to save the engineer from unnecessary rework. Yet, tools are not capable of keeping up with the engineers' rate of model changes. This paper presents an approach for quickly, correctly, and automatically deciding what consistency rules to evaluate when a model changes. The approach does not require consistency rules with special annotations. Instead, it treats consistency rules as black-box entities and observes their behavior during their evaluation to identify what model elements they access. The UML/Analyzer tool, integrated with IBM Rational Rose™, fully implements this approach. It was used to evaluate 29 models with tens-of-thousands of model elements, evaluated on 24 types of consistency rules over 140,000 times. We found that the approach provided design feedback correctly and required, in average, less than 9ms evaluation time per model change with a worst case of less than 2 seconds at the expense of a linearly increasing memory need. This is a significant improvement over the state-of-the-art.},
keywords={Consistency; Used},
url={https://search.proquest.com/docview/31397839},
doi={10.1145/1134285.1134339},
publisher={ACM},
year={2006},
}

@thesis{RefWorks:RefID:25-nentwich2005managing,
author={Nentwich,Christian},
title={Managing the consistency of distributed documents},
abstract={Many businesses produce documents as part of their daily activities: software engineers produce requirements specifications, design models, source code, build scripts and more; business analysts produce glossaries, use cases, organisation charts, and domain ontology models; service providers and retailers produce catalogues, customer data, purchase orders, invoices and web pages. What these examples have in common is that the content of documents is often semantically related: source code should be consistent with the design model, a domain ontology may refer to employees in an organisation chart, and invoices to customers should be consistent with stored customer data and purchase orders. As businesses grow and documents are added, it becomes difficult to manually track and check the increasingly complex relationships between documents. The problem is compounded by current trends towards distributed working, either over the Internet or over a global corporate network in large organisations. This adds complexity as related information is not only scattered over a number of documents, but the documents themselves are distributed across multiple physical locations. This thesis addresses the problem of managing the consistency of distributed and possibly heterogeneous documents. “Documents” is used here as an abstract term, and does not necessarily refer to a human readable textual representation. We use the word to stand for a file or data source holding structured information, like a database table, or some source of semi-structured information, like a file of comma-separated values or a document represented in a hypertext markup language like XML [Bray et al., 2000]. Document heterogeneity comes into play when data with similar semantics is represented in different ways: for example, a design model may store a class as a rectangle in a diagram whereas a source code file will embed it as a textual string; and an invoice may contain an invoice identifier that is composed of a customer name and date, both of which may be recorded and managed separately. Consistency management in this setting encompasses a number of steps. Firstly, checks must be executed in order to determine the consistency status of documents. Documents are inconsistent if their internal elements hold values that do not meet the properties expected in the application domain or if there are conflicts between the values of elements in multiple documents. The results of a consistency check have to be accumulated and reported back to the user. And finally, the user may choose to change the documents to bring them into a consistent state. The current generation of tools and techniques is not always sufficiently equipped to deal with this problem. Consistency checking is mostly tightly integrated or hardcoded into tools, leading to problems with extensibility with respect to new types of documents. Many tools do not support checks of distributed data, insisting instead on accumulating everything in a centralized repository. This may not always be possible, due to organisational or time constraints, and can represent excessive overhead if the only purpose of integration is to improve data consistency rather than deriving any additional benefit. This thesis investigates the theoretical background and practical support necessary to support consistency management of distributed documents. It makes a number of contributions to the state of the art, and the overall approach is validated in significant case studies that provide evidence of its practicality and usefulness.},
keywords={Consistency; Document; Used},
url={http://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.416649},
year={2005},
}

@inbook{RefWorks:RefID:24-brucker2019ontologies,
author={Brucker,Achim D. and Wolff,Burkhart},
title={Using Ontologies in Formal Developments Targeting Certification},
booktitle ={Integrated Formal Methods},
publisher={Springer International Publishing},
address={Cham},
volume={11918},
pages={65–82},
abstract={A common problem in the certification of highly safety or security critical systems is the consistency of the certification documentation in general and, in particular, the linking between semi-formal and formal content of the certification documentation.
We address this problem by using an existing framework, , that allows writing certification documents with consistency guarantees, in both, the semi-formal and formal parts. supports the modeling of document ontologies using a strongly typed ontology definition language. An ontology is then enforced inside documents including formal parts, e. g., system models, verification proofs, code, tests and validations of corner-cases. The entire set of documents is checked within Isabelle/HOL, which includes the definition of ontologies and the editing of integrated documents based on them. This process is supported by an IDE that provides continuous checking of the document consistency.
In this paper, we present how a specific software-engineering certification standard, namely CENELEC 50128, can be modeled inside . Based on an ontology covering a substantial part of this standard, we present how can be applied to a certification case-study in the railway domain.},
keywords={Ontology; Document; Used},
isbn={9783030349677},
url={http://link.springer.com/10.1007/978-3-030-34968-4_4},
doi={10.1007/978-3-030-34968-4_4},
year={2019},
translator={Anonymous },
}

@article{RefWorks:RefID:23-weitl2006checking,
author={Weitl,Franz and Freitag,Burkhard},
title={Checking Content Consistency of Integrated Web Documents},
journal={Journal of computer science and technology},
volume={21},
number={3},
pages={418–429},
abstract={A conceptual framework for the specification and verification of constraints on the content and narrative structure of documents is proposed. As a specification formalism, CTL is defined, which is an extension of the temporal logic CTL by description logic concepts. In contrast to existing solutions this approach allows for the integration of ontologies to achieve interoperability and abstraction from implementation aspects of documents. This makes CTL specifically suitable for the integration of heterogeneous and distributed information resources in the semantic web.},
keywords={Consistency; Document; Used}, issn={1000-9000},
doi={10.1007/s11390-006-0418-9},
year={2006},
url={https://www.proquest.com/docview/912145578/abstract/},
}

@article{RefWorks:RefID:21-heitmeyer1996automated,
author={Heitmeyer,Constance L. and Jeffords,Ralph D. and Labaw,Bruce G.},
title={Automated consistency checking of requirements specifications},
journal={ACM transactions on software engineering and methodology},
volume={5},
number={3},
pages={231–261},
abstract={This article describes a formal analysis technique, called consistency checking, for automatic detection of errors, such as type errors, nondeterminism, missing cases, and circular definitions, in requirements specifications. The technique is designed to analyze requirements specifications expressed in the SCR (Software Cost Reduction) tabular notation. As background, the SCR approach to specifying requirements is reviewed. To provide a formal semantics for the SCR notation and a foundation for consistency checking, a formal requirements model is introduced; the model represents a software system as a finite-state automation which produces externally visible outputs in response to changes in monitored environmental quantities. Results of two experiments are presented which evaluated the utility and scalability of our technique for consistency checking in real-world avionics application. The role of consistency checking during the requirements phase of software development is discussed.},
keywords={Consistency; Document; Used}, issn={1049-331X},
doi={10.1145/234426.234431},
year={1996},
url={https://dl.acm.org/doi/10.1145/234426.234431},
}

@article{RefWorks:RefID:19-schönberg2011verifying,
author={Schönberg,Christian and Weitl,Franz and Freitag,Burkhard},
title={Verifying the consistency of web-based technical documentations},
journal={Journal of symbolic computation},
volume={46},
number={2},
pages={183–206},
abstract={A new framework for document verification is presented which covers the entire process from document analysis through information extraction, document modeling, representation of background knowledge about the domain of discourse, user level and formal representation of consistency criteria, verification by model checking, counterexample generation, and error reporting. Emphasis is placed on employing background knowledge to reduce the complexity and to increase the quality of results in each step. A rule-based approach to information extraction supports the concise definition of extraction rules for document formats based on XML or HTML. The expressiveness of the existing extraction methods is exceeded by supporting rule specialization, integration of external tools, and access to background knowledge represented in ontologies. As a formal basis for representing consistency criteria, the new temporal description logic
ALC
CTL
is proposed. In contrast to the existing formalisms, criteria related to the coherence of content along individual paths of reading can be represented and verified efficiently. The adequacy, performance, and effectiveness of the proposed framework is demonstrated on a case study in technical documentation.},
keywords={Consistency; Document; Used}, issn={0747-7171},
doi={10.1016/j.jsc.2010.08.007},
year={2011},
url={https://dx.doi.org/10.1016/j.jsc.2010.08.007},
}

@article{RefWorks:RefID:14-shen2021evaluating,
author={Shen,Aili and Mistica,Meladel and Salehi,Bahar and Li,Hang and Baldwin,Timothy and Qi,Jianzhong},
title={Evaluating Document Coherence Modeling},
journal={Transactions of the Association for Computational Linguistics},
volume={9},
pages={621–640},
abstract={While pretrained language models (LMs) have driven impressive gains over morpho-syntactic and semantic tasks, their ability to model discourse and pragmatic phenomena is less clear. As a step towards a better understanding of their discourse modeling capabilities, we propose a sentence intrusion detection task. We examine the performance of a broad range of pretrained LMs on this detection task for English. Lacking a dataset for the task, we introduce INSteD, a novel  dataset, containing 170,000+ documents constructed from English Wikipedia and CNN news articles. Our experiments show that pretrained LMs perform impressively in in-domain evaluation, but experience a substantial drop in the cross-domain setting, indicating limited generalization capacity. Further results over a novel linguistic probe dataset show that there is substantial room for improvement, especially in the cross- domain setting.},
keywords={Coherence; Document; Used}, issn={2307-387X},
doi={10.1162/tacl_a_00388},
year={2021},
url={https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00388},
}

@conference{RefWorks:RefID:13-laban2021transformer,
author={Laban,Philippe and Dai,Luke and Bandarkar,Lucas and Hearst,Marti A.},
editor={Zong,Chengqing and Xia,Fei and Li,Wenjie and Navigli,Roberto},
title={Can Transformer Models Measure Coherence In Text? Re-Thinking the Shuffle Test},
booktitle={59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing},
publisher={Association for Computational Linguistics},
address={Online},
pages={1058–1064},
note={I had to change percent to \% for LaTeX.},
abstract={Association for Computational Linguistics (2021) The Shuffle Test is the most common task to evaluate whether NLP models can
measure coherence in text. Most recent work uses direct supervision on the
task; we show that by simply finetuning a RoBERTa model, we can achieve a near
perfect accuracy of 97.8\%, a state-of-the-art. We argue that this outstanding
performance is unlikely to lead to a good model of text coherence, and suggest
that the Shuffle Test should be approached in a Zero-Shot setting: models
should be evaluated without being trained on the task itself. We evaluate
common models in this setting, such as Generative and Bi-directional
Transformers, and find that larger architectures achieve high-performance
out-of-the-box. Finally, we suggest the k-Block Shuffle Test, a modification of
the original by increasing the size of blocks shuffled. Even though human
reader performance remains high (around 95\% accuracy), model performance drops
from 94\% to 78\% as block size increases, creating a conceptually simple
challenge to benchmark NLP models. Code available:
https://github.com/tingofurro/shuffle\_test/},
keywords={Coherence; Document; Transformer; Used},
url={https://arxiv.org/abs/2107.03448},
doi={10.18653/v1/2021.acl-short.134},
publisher={Association for Computational Linguistics},
year={2021},
}

@conference{RefWorks:RefID:11-aumiller2021structural,
author={Aumiller,Dennis and Almasian,Satya and Lackner,Sebastian and Gertz,Michael},
editor={ },
title={Structural text segmentation of legal documents},
booktitle={Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law},
publisher={ACM},
address={New York, NY, USA},
pages={2–11},
abstract={The growing complexity of legal cases has lead to an increasing interest in legal information retrieval systems that can effectively satisfy user-specific information needs. However, such downstream systems typically require documents to be properly formatted and segmented, which is often done with relatively simple pre-processing steps, disregarding topical coherence of segments. Systems generally rely on representations of individual sentences or paragraphs, which may lack crucial context, or document-level representations, which are too long for meaningful search results. To address this issue, we propose a segmentation system that can predict topical coherence of sequential text segments spanning several paragraphs, effectively segmenting a document and providing a more balanced representation for downstream applications. We build our model on top of popular transformer networks and formulate structural text segmentation as topical change detection, by performing a series of independent classifications that allow for efficient fine-tuning on task-specific data. We crawl a novel dataset consisting of roughly 74,000 online Terms-of-Service documents, including hierarchical topic annotations, which we use for training. Results show that our proposed system significantly outperforms baselines, and adapts well to structural peculiarities of legal documents. We release both data and trained models to the research community for future work.1},
keywords={Law; Document; Used},
doi={10.1145/3462757.3466085},
publisher={ACM},
year={2021},
}

@article{RefWorks:RefID:10-zowghi2003interplay,
author={Zowghi,Didar and Gervasi,Vincenzo},
title={On the interplay between consistency, completeness, and correctness in requirements evolution},
journal={Information and Software Technology},
volume={45},
number={14},
pages={993–1009},
abstract={The initial expression of requirements for a computer-based system is often informal and possibly vague. Requirements engineers need to examine this often incomplete and inconsistent brief expression of needs. Based on the available knowledge and expertise, assumptions are made and conclusions are deduced to transform this ‘rough sketch’ into more complete, consistent, and hence correct requirements. This paper addresses the question of how to characterize these properties in an evolutionary framework, and what relationships link these properties to a customer's view of correctness. Moreover, we describe in rigorous terms the different kinds of validation checks that must be performed on different parts of a requirements specification in order to ensure that errors (i.e. cases of inconsistency and incompleteness) are detected and marked as such, leading to better quality requirements.},
keywords={Consistency; Completeness; Document; Used}, issn={0950-5849},
doi={10.1016/S0950-5849(03)00100-9},
year={2003},
url={https://dx.doi.org/10.1016/S0950-5849(03)00100-9},
}

@article{RefWorks:RefID:7-gupta2021graph,
author={Gupta,Atika and Matta,Priya and Pant,Bhasker},
title={Graph neural network: Current state of Art, challenges and applications},
journal={Materials today : proceedings},
volume={46},
pages={10927–10932},
abstract={Several areas in science and engineering have the relationships between their underlying data which can be represented as graphs, for example, molecular chemistry, node prediction, link prediction, computer vision, pattern recognition, social networking and more. In this article, an approach to a model which can handle such type of data is elaborated, which is Graph Neural Networks (GNN). GNN encompasses the neural network technique to process the data which is represented as graphs. Due to its massive success, GNN has made its way into many applications and is a popular architecture to work upon. This paper explains the graph neural networks, its area of applications and its day-to-day use in our daily lives. Some of the very common application is a social networking site which is on our hands regularly, and another could be the recommendation system which recommends us friends, or the products of our interest based on our pat choices and preferences. This paper also demonstrates the basic challenges encountered while implementing GNN. This paper will be a great help to those researchers who are keen to work in the domain of GNN.},
keywords={GNN; Used}, issn={2214-7853},
doi={10.1016/j.matpr.2021.01.950},
year={2021},
url={https://dx.doi.org/10.1016/j.matpr.2021.01.950},
}

@article{RefWorks:RefID:6-2022knowledge,
author={Ling Tian and Xue Zhou and Yan-Ping Wu and Wang-Tao Zhou and Jin-Hao Zhang and Tian-Shu Zhang},
title={Knowledge graph and knowledge reasoning: A systematic review},
journal={Journal of Electronic Science and Technology},
volume={20},
number={2},
pages={100159},
abstract={The knowledge graph (KG) that represents structural relations among entities has become an increasingly important research field for knowledge-driven artificial intelligence. In this survey, a comprehensive review of KG and KG reasoning is provided. It introduces an overview of KGs, including representation, storage, and essential technologies. Specifically, it summarizes several types of knowledge reasoning approaches, including logic rules-based, representation-based, and neural network-based methods. Moreover, this paper analyzes the representation methods of knowledge hypergraphs. To effectively model hyper-relational data and improve the performance of knowledge reasoning, a three-layer knowledge hypergraph model is proposed. Finally, it analyzes the advantages of three-layer knowledge hypergraphs through reasoning and update algorithms which could facilitate future research.},
keywords={Knowledge Graph; Ontology; Survey; Used},
year={2022},
url={https://doaj.org/article/fc808085fb154c6c9b032ac617e9f233},
}

@report{RefWorks:RefID:5-chaurasiya2022entity,
author={Chaurasiya,Deepak and Surisetty,Anil and Kumar,Nitish and Singh,Alok and Dey,Vikrant and Malhotra,Aakarsh and Dhama,Gaurav and Arora,Ankur},
title={Entity Alignment For Knowledge Graphs: Progress, Challenges, and Empirical Studies},
journal={Cornell University},
abstract={Entity Alignment (EA) identifies entities across databases that refer to the
same entity. Knowledge graph-based embedding methods have recently dominated EA
techniques. Such methods map entities to a low-dimension space and align them
based on their similarities. With the corpus of EA methodologies growing
rapidly, this paper presents a comprehensive analysis of various existing EA
methods, elaborating their applications and limitations. Further, we
distinguish the methods based on their underlying algorithms and the
information they incorporate to learn entity representations. Based on
challenges in industrial datasets, we bring forward 4 research questions
(RQs). These RQs empirically analyse the algorithms from the perspective of
\textit{Hubness, Degree distribution, Non-isomorphic neighbourhood,} and
\textit{Name bias}. For Hubness, where one entity turns up as the nearest
neighbour of many other entities, we define an h-score to quantify its effect
on the performance of various algorithms. Additionally, we try to level the
playing field for algorithms that rely primarily on name-bias existing in the
benchmarking open-source datasets by creating a low name bias dataset. We
further create an open-source repository for 14 embedding-based EA methods
and present the analysis for invoking further research motivations in the field
of EA.},
keywords={Ontology; Knowledge Graph; Used; Named Entity Recognition},
url={https://arxiv.org/abs/2205.08777},
doi={10.48550/arxiv.2205.08777},
year={2022},
}

@article{RefWorks:RefID:4-al-moslmi2020named,
author={Al-Moslmi,Tareq and Gallofre Ocana,Marc and L. Opdahl,Andreas and Veres,Csaba},
title={Named Entity Extraction for Knowledge Graphs: A Literature Overview},
journal={IEEE access},
volume={8},
pages={32862–32881},
abstract={An enormous amount of digital information is expressed as natural-language (NL) text that is not easily processable by computers. Knowledge Graphs (KG) offer a widely used format for representing information in computer-processable form. Natural Language Processing (NLP) is therefore needed for mining (or lifting) knowledge graphs from NL texts. A central part of the problem is to extract the named entities in the text. The paper presents an overview of recent advances in this area, covering: Named Entity Recognition (NER), Named Entity Disambiguation (NED), and Named Entity Linking (NEL). We comment that many approaches to NED and NEL are based on older approaches to NER and need to leverage the outputs of state-of-the-art NER systems. There is also a need for standard methods to evaluate and compare named-entity extraction approaches. We observe that NEL has recently moved from being stepwise and isolated into an integrated process along two dimensions: the first is that previously sequential steps are now being integrated into end-to-end processes, and the second is that entities that were previously analysed in isolation are now being lifted in each other's context. The current culmination of these trends are the deep-learning approaches that have recently reported promising results.},
keywords={Document; Knowledge Graph; Ontology; Survey; Used; Named Entity Recognition}, issn={2169-3536},
doi={10.1109/ACCESS.2020.2973928},
year={2020},
url={https://ieeexplore.ieee.org/document/8999622},
}